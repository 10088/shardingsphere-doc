1,3c1,3
< commit 002f48fb8fd465f1f6deb598a3fd485d8321a47e
< Author: 邱鹿 Lucas <lucas307@163.com>
< Date:   Mon Oct 12 18:25:41 2020 +0800
---
> commit be42925d34b0fbbe799df379871bc16ba08db29b
> Author: yang-7777 <67564630+yang-7777@users.noreply.github.com>
> Date:   Tue Oct 13 10:59:53 2020 +0800
5c5
<     Update scaling documents and configuration (#7757)
---
>     Update result.en.md (#7756)
7,11c7
<     * update documents and conf.
<     
<     * Update scaling documents and configuration
<     
<     Co-authored-by: qiulu3 <Lucas209910>
---
>     add a pic in the summary section
13,28c9,16
< diff --git a/docs/document/content/user-manual/shardingsphere-scaling/build.cn.md b/docs/document/content/user-manual/shardingsphere-scaling/build.cn.md
< index 6f75a248fd..5fbae41cc0 100644
< --- a/docs/document/content/user-manual/shardingsphere-scaling/build.cn.md
< +++ b/docs/document/content/user-manual/shardingsphere-scaling/build.cn.md
< @@ -17,13 +17,21 @@ mvn clean install -Prelease;
<  
<  发布包所在目录为：`/shardingsphere-distribution/shardingsphere-scaling-distribution/target/apache-shardingsphere-${latest.release.version}-shardingsphere-scaling-bin.tar.gz`。
<  
< -2. 解压缩发布包，修改配置文件 `conf/server.yaml`，这里主要修改启动端口，保证不与本机其他端口冲突，其他值保持默认即可：
< +2. 解压缩发布包，修改配置文件 `conf/server.yaml`，这里主要修改启动端口，保证不与本机其他端口冲突，同时修改断点续传服务（可选）地址即可：
<  
<  ```
<  port: 8888
<  blockQueueSize: 10000
<  pushTimeout: 1000
<  workerThread: 30
---
> diff --git a/docs/blog/content/material/result.en.md b/docs/blog/content/material/result.en.md
> index 71e100da8f..89fc0d753c 100644
> --- a/docs/blog/content/material/result.en.md
> +++ b/docs/blog/content/material/result.en.md
> @@ -23,12 +23,12 @@ Since the result set returned from the database is returned one by one, it is no
>  Streaming merge means that each time the data is fetched from the result set, the correct individual data can be returned by fetching it one by one, which is most compatible with the way the database returns the result set natively. Traversal, sorting, and Stream Group-by Merger are all types of stream imputation.
>  
>  In-memory merging, on the other hand, requires that all data in the result set be traversed and stored in memory, and then after unified grouping, sorting, and aggregation calculations, it is encapsulated to return the result set of data accessed one item at a time.
30,44c18,34
< +resumeBreakPoint:
< +  name: scalingJob
< +  registryCenter:
< +    type: ZooKeeper
< +    serverLists: localhost:2181
< +    props:
< +      retryIntervalMilliseconds: 10000
<  ```
<  
<  3. 启动 ShardingSphere-Scaling：
< @@ -62,4 +70,5 @@ curl -X GET http://localhost:8888/scaling/job/list
<  | blockQueueSize | 数据传输通道队列大小                      | 10000  |
<  | pushTimeout    | 数据推送超时时间，单位：毫秒               | 1000   |
<  | workerThread   | 工作线程池大小，允许同时运行的迁移任务线程数 | 30     |
< +| resumeBreakPoint   | 断点续传服务                         |        |
---
>  The decorator merge is a unified functional enhancement of all the result set merge, currently the decorator merge only paging this type of merge.
>  
>  
>  ### Categorization
>  
> -
>  #### Iteration Merger 
>  It is the simplest form of aggregation. Simply merge multiple result sets into a one-way chain table. After iterating through the current result set in the chain table, move the chain table element back one place and continue to iterate through the next result set.
>  
> @@ -112,11 +112,13 @@ Sharding-Sphere's Pagination capabilities are rather misleading to users, who of
>  
>  However, it is also important to note that a large amount of data still needs to be transferred to Sharding-Sphere's memory space due to the sorting needs. Therefore, it is not a best practice to use LIMIT for Pagination in this manner. Since LIMIT does not query data by index, Pagination by ID is a better solution if continuity of ID can be guaranteed, e.g..
>  
> -
>  ![](https://shardingsphere.apache.org/blog/img/result7.jpg)
>    
>  Or by recording the ID of the last record of the last query result for the next page, for example.
46,61c36,39
< diff --git a/docs/document/content/user-manual/shardingsphere-scaling/build.en.md b/docs/document/content/user-manual/shardingsphere-scaling/build.en.md
< index 000e851f9e..690b963006 100644
< --- a/docs/document/content/user-manual/shardingsphere-scaling/build.en.md
< +++ b/docs/document/content/user-manual/shardingsphere-scaling/build.en.md
< @@ -16,13 +16,21 @@ mvn clean install -Prelease;
<  
<  The binary package's directory is:`/shardingsphere-distribution/shardingsphere-scaling-distribution/target/apache-shardingsphere-${latest.release.version}-shardingsphere-scaling-bin.tar.gz`。
<  
< -2. Unzip the distribution package, modify the configuration file `conf/server.yaml`, we should ensure the port does not conflict with others, and other values can be left as default:
< +2. Unzip the distribution package, modify the configuration file `conf/server.yaml`, we should ensure the port does not conflict with others, and modify the resume from break-point(optional) server lists:
<  
<  ```
<  port: 8888
<  blockQueueSize: 10000
<  pushTimeout: 1000
<  workerThread: 30
---
> - 
>  ![](https://shardingsphere.apache.org/blog/img/result8.jpg)
>  
> +### Summary
63,77c41,42
< +resumeBreakPoint:
< +  name: scalingJob
< +  registryCenter:
< +    type: ZooKeeper
< +    serverLists: localhost:2181
< +    props:
< +      retryIntervalMilliseconds: 10000
<  ```
<  
<  3. Start up ShardingSphere-Scaling:
< @@ -61,3 +69,4 @@ response:
<  | blockQueueSize | Queue size of data transmission channel                                                   | 10000         |
<  | pushTimeout    | Data push timeout(ms)                                                                     | 1000          |
<  | workerThread   | Worker thread pool size, the number of migration task threads allowed to run concurrently | 30            |
< +| resumeBreakPoint   | Resume from break-point service                                                       |               |
---
> +The whole structure of merger engine is showing below:
> +![](https://shardingsphere.apache.org/blog/img/result10.png)
