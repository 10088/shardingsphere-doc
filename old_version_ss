commit 47791a647597b222309a5273ccbcd5e28b6b24f4
Author: Mike0601 <40025573+Mike0601@users.noreply.github.com>
Date:   Tue Aug 23 17:09:31 2022 +0800

    Update doc: change scaling into data migration (#20459)

diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.cn.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.cn.md
index f7262d339c9..e6d59dca468 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.cn.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.cn.md
@@ -1,10 +1,10 @@
 +++
-title = "Scaling"
+title = "数据迁移"
 weight = 4
 +++
 
 ## 简介
 
-ShardingSphere-Scaling 是一个提供给用户的通用的 ShardingSphere 数据接入迁移，及弹性伸缩的解决方案。
+ShardingSphere 可以提供给用户通用的数据迁移解决方案。
 
 于 **4.1.0** 开始向用户提供，目前仍处于 **实验室** 版本。
diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.en.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.en.md
index 4dee8cdd987..24ea0d3825f 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.en.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/_index.en.md
@@ -1,8 +1,8 @@
 +++
-title = "Scaling"
+title = "Data Migration"
 weight = 4
 +++
 
 ## Introduction
 
-ShardingSphere-Scaling is a common solution for migrating data to ShardingSphere or scaling data in Apache ShardingSphere since **4.1.0**, current state is **Experimental** version.
+ShardingSphere provides solution of migrating data since **4.1.0**, current state is **Experimental** version.
diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.cn.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.cn.md
index 51247f8a796..cd64cc4609a 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.cn.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.cn.md
@@ -3,7 +3,16 @@ title = "运行部署"
 weight = 1
 +++
 
-## 部署启动
+## 背景信息
+
+对于使用单数据库运行的系统来说，如何安全简单地将数据迁移至水平分片的数据库上，一直以来都是一个迫切的需求。
+
+## 前提条件
+
+-  Proxy 采用纯  JAVA 开发，JDK 建议 1.8 或以上版本。
+- 数据迁移使用集群模式，目前支持 ZooKeeper 作为注册中心。
+
+## 操作步骤
 
 1. 执行以下命令，编译生成 ShardingSphere-Proxy 二进制包：
 
@@ -18,8 +27,6 @@ mvn clean install -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true -Drat.skip=tr
 
 或者通过[下载页面]( https://shardingsphere.apache.org/document/current/cn/downloads/ )获取安装包。
 
-> Scaling 还是实验性质的功能，建议使用 master 分支最新版本，点击此处[下载每日构建版本]( https://github.com/apache/shardingsphere#nightly-builds )
-
 2. 解压缩 proxy 发布包，修改配置文件 `conf/config-sharding.yaml`。详情请参见 [proxy 启动手册](/cn/user-manual/shardingsphere-proxy/startup/bin/)。
 
 3. 修改配置文件 `conf/server.yaml`，详情请参见[模式配置](/cn/user-manual/shardingsphere-jdbc/yaml-config/mode/)。
@@ -42,176 +49,136 @@ mode:
   overwrite: false
 ```
 
-4. 开启 scaling。
+4. 引入 JDBC 驱动。
+
+如果后端连接以下数据库，请下载相应 JDBC 驱动 jar 包，并将其放入 `${shardingsphere-proxy}/lib` 目录。
 
-方法1：修改配置文件 `conf/config-sharding.yaml` 的 `scalingName` 和 `scaling` 部分。
+| 数据库                 | JDBC 驱动                                                                                                                                                          | 参考                                                                                             |
+| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------ |
+| MySQL                 | [mysql-connector-java-5.1.47.jar]( https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar )                              | [Connector/J Versions]( https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-versions.html ) |
+| openGauss             | [opengauss-jdbc-2.0.1-compatibility.jar]( https://repo1.maven.org/maven2/org/opengauss/opengauss-jdbc/2.0.1-compatibility/opengauss-jdbc-2.0.1-compatibility.jar ) |                                                                                                  |
 
-配置项说明：
-```yaml
-rules:
-- !SHARDING
-  # 忽略的配置
-  
-  scalingName: # 启用的弹性伸缩配置名称
-  scaling:
-    <scaling-action-config-name> (+):
-      input: # 数据读取配置。如果不配置则部分参数默认生效。
-        workerThread: # 从源端摄取全量数据的线程池大小。如果不配置则使用默认值。
-        batchSize: # 一次查询操作返回的最大记录数。如果不配置则使用默认值。
-        rateLimiter: # 限流算法。如果不配置则不限流。
-          type: # 算法类型。可选项：QPS
-          props: # 算法属性
-            qps: # qps属性。适用算法类型：QPS
-      output: # 数据写入配置。如果不配置则部分参数默认生效。
-        workerThread: # 数据写入到目标端的线程池大小。如果不配置则使用默认值。
-        batchSize: # 一次批量写入操作的最大记录数。如果不配置则使用默认值。
-        rateLimiter: # 限流算法。如果不配置则不限流。
-          type: # 算法类型。可选项：TPS
-          props: # 算法属性
-            tps: # tps属性。适用算法类型：TPS
-      streamChannel: # 数据通道，连接生产者和消费者，用于 input 和 output 环节。如果不配置则默认使用 MEMORY 类型
-        type: # 算法类型。可选项：MEMORY
-        props: # 算法属性
-          block-queue-size: # 属性：阻塞队列大小
-      completionDetector: # 作业是否接近完成检测算法。如果不配置则无法自动进行后续步骤，可以通过 DistSQL 手动操作。
-        type: # 算法类型。可选项：IDLE
-        props: # 算法属性
-          incremental-task-idle-seconds-threshold: # 如果增量同步任务不再活动超过一定时间，那么可以认为增量同步任务接近完成。适用算法类型：IDLE
-      dataConsistencyChecker: # 数据一致性校验算法。如果不配置则跳过这个步骤。
-        type: # 算法类型。可选项：DATA_MATCH, CRC32_MATCH
-        props: # 算法属性
-          chunk-size: # 一次查询操作返回的最大记录数
+5. 启动 ShardingSphere-Proxy：
+
+```
+sh bin/start.sh
 ```
 
-`dataConsistencyChecker` 的 `type` 可以通过执行 DistSQL `SHOW MIGRATION CHECK ALGORITHMS` 查询到。简单对比：
-- `DATA_MATCH`：支持所有数据库，但是性能不是最好的。
-- `CRC32_MATCH`：只支持 `MySQL`，但是性能更好。
+6. 查看 proxy 日志 `logs/stdout.log`，看到日志中出现：
 
-自动模式配置示例：
-```yaml
-rules:
-- !SHARDING
-  # 忽略的配置
-  
-  scalingName: scaling_auto
-  scaling:
-    scaling_auto:
-      input:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: QPS
-          props:
-            qps: 50
-      output:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: TPS
-          props:
-            tps: 2000
-      streamChannel:
-        type: MEMORY
-        props:
-          block-queue-size: 10000
-      completionDetector:
-        type: IDLE
-        props:
-          incremental-task-idle-seconds-threshold: 1800
-      dataConsistencyChecker:
-        type: DATA_MATCH
-        props:
-          chunk-size: 1000
+```
+[INFO ] [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy start success
 ```
 
-手动模式配置示例：
-```yaml
-rules:
-- !SHARDING
-  # 忽略的配置
-  
-  scalingName: scaling_manual
-  scaling:
-    scaling_manual:
-      input:
-        workerThread: 40
-        batchSize: 1000
-      output:
-        workerThread: 40
-        batchSize: 1000
-      streamChannel:
-        type: MEMORY
-        props:
-          block-queue-size: 10000
-      dataConsistencyChecker:
-        type: DATA_MATCH
-        props:
-          chunk-size: 1000
+确认启动成功。
+
+7. 按需配置迁移
+
+7.1. 查询配置。
+
+```sql
+SHOW MIGRATION PROCESS CONFIGURATION;
 ```
 
-方法2：通过 DistSQL 配置 scaling
+默认配置如下：
 
-自动模式配置示例：
 ```sql
-CREATE SHARDING SCALING RULE scaling_auto (
-INPUT(
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
+| read                                                         | write                                | stream_channel                                       |
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
+| {"workerThread":40,"batchSize":1000,"shardingSize":10000000} | {"workerThread":40,"batchSize":1000} | {"type":"MEMORY","props":{"block-queue-size":10000}} |
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
+
+
+7.2. 新建配置（可选）。
+
+不配置的话有默认值。
+
+完整配置 DistSQL 示例：
+
+```DistSQL
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ(
   WORKER_THREAD=40,
   BATCH_SIZE=1000,
-  RATE_LIMITER(TYPE(NAME=QPS, PROPERTIES("qps"=50)))
+  SHARDING_SIZE=10000000,
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='500')))
 ),
-OUTPUT(
+WRITE(
   WORKER_THREAD=40,
   BATCH_SIZE=1000,
-  RATE_LIMITER(TYPE(NAME=TPS, PROPERTIES("tps"=2000)))
+  RATE_LIMITER (TYPE(NAME='TPS',PROPERTIES('tps'='2000')))
 ),
-STREAM_CHANNEL(TYPE(NAME="MEMORY", PROPERTIES("block-queue-size"="10000"))),
-COMPLETION_DETECTOR(TYPE(NAME="IDLE", PROPERTIES("incremental-task-idle-seconds-threshold"="1800"))),
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="DATA_MATCH", PROPERTIES("chunk-size"="1000")))
+STREAM_CHANNEL (TYPE(NAME='MEMORY',PROPERTIES('block-queue-size'='10000')))
 );
 ```
 
-手动模式配置示例：
+配置项说明：
+
 ```sql
-CREATE SHARDING SCALING RULE scaling_manual (
-INPUT(
-  WORKER_THREAD=40,
-  BATCH_SIZE=1000
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ( -- 数据读取配置。如果不配置则部分参数默认生效。
+  WORKER_THREAD=40, -- 从源端摄取全量数据的线程池大小。如果不配置则使用默认值。
+  BATCH_SIZE=1000, -- 一次查询操作返回的最大记录数。如果不配置则使用默认值。
+  SHARDING_SIZE=10000000, -- 全量数据分片大小。如果不配置则使用默认值。
+  RATE_LIMITER ( -- 限流算法。如果不配置则不限流。
+  TYPE( -- 算法类型。可选项：QPS
+  NAME='QPS',
+  PROPERTIES( -- 算法属性
+  'qps'='500'
+  )))
 ),
-OUTPUT(
-  WORKER_THREAD=40,
-  BATCH_SIZE=1000
+WRITE( -- 数据写入配置。如果不配置则部分参数默认生效。
+  WORKER_THREAD=40, -- 数据写入到目标端的线程池大小。如果不配置则使用默认值。
+  BATCH_SIZE=1000, -- 一次批量写入操作的最大记录数。如果不配置则使用默认值。
+  RATE_LIMITER ( -- 限流算法。如果不配置则不限流。
+  TYPE( -- 算法类型。可选项：TPS
+  NAME='TPS',
+  PROPERTIES( -- 算法属性
+  'tps'='2000'
+  )))
 ),
-STREAM_CHANNEL(TYPE(NAME="MEMORY", PROPERTIES("block-queue-size"="10000"))),
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="DATA_MATCH", PROPERTIES("chunk-size"="1000")))
+STREAM_CHANNEL ( -- 数据通道，连接生产者和消费者，用于 read 和 write 环节。如果不配置则默认使用 MEMORY 类型。
+TYPE( -- 算法类型。可选项：MEMORY
+NAME='MEMORY',
+PROPERTIES( -- 算法属性
+'block-queue-size'='10000' -- 属性：阻塞队列大小
+)))
 );
 ```
 
-详情请参见 [RDL#数据分片](/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/)。
+DistSQL 示例：配置 `READ` 限流。
 
-5. 引入 JDBC 驱动
-
-如果后端连接以下数据库，请下载相应 JDBC 驱动 jar 包，并将其放入 `${shardingsphere-proxy}/lib` 目录。
-
-| 数据库                 | JDBC 驱动                              | 参考                 |
-| --------------------- | ------------------------------------ | -------------------- |
-| MySQL                 | [mysql-connector-java-5.1.47.jar]( https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar ) | [Connector/J Versions]( https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-versions.html ) |
-
-6. 启动 ShardingSphere-Proxy：
-
-```
-sh bin/start.sh
+```sql
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='500')))
+)
+);
 ```
 
-7. 查看 proxy 日志 `logs/stdout.log`，看到日志中出现：
+配置读取数据限流，其它配置使用默认值。
 
-```
-[INFO ] [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy start success
-```
+7.3. 修改配置。
 
-确认启动成功。
+`ALTER MIGRATION PROCESS CONFIGURATION`，内部结构和 `CREATE MIGRATION PROCESS CONFIGURATION` 一致。
 
-## 结束
+DistSQL 示例：调整限流参数
 
+```sql
+ALTER MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+)
+);
+---
+ALTER MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+), WRITE(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+)
+);
 ```
- sh bin/stop.sh
-```
+
+DistSQL 示例：清空 `READ` 配置、恢复为默认值。
diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.en.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.en.md
index 594f87bdedd..64ed6bc14b4 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.en.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/build.en.md
@@ -3,9 +3,18 @@ title = "Build"
 weight = 1
 +++
 
-## Build&Deployment
+## Background
 
-1. Execute the following command to compile and generate the ShardingSphere-Proxy binary package:
+For systems running on a single database that urgently need to securely and simply migrate data to a horizontally sharded database.
+
+## Prerequisites
+
+-  Proxy is developed in JAVA, and JDK version 1.8 or later is recommended. 
+- Data migration adopts the cluster mode, and ZooKeeper is currently supported as the registry.
+
+## Procedure
+
+1. Run the following command to compile the ShardingSphere-Proxy binary package: 
 
 ```
 git clone --depth 1 https://github.com/apache/shardingsphere.git
@@ -13,19 +22,18 @@ cd shardingsphere
 mvn clean install -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true -Drat.skip=true -Djacoco.skip=true -DskipITs -DskipTests -Prelease
 ```
 
-The binary packages:
+Release package：
 - /shardingsphere-distribution/shardingsphere-proxy-distribution/target/apache-shardingsphere-${latest.release.version}-shardingsphere-proxy-bin.tar.gz
 
-Or get binary package from [download page]( https://shardingsphere.apache.org/document/current/en/downloads/ ).
+Or you can get the installation package through the [Download Page](https://shardingsphere.apache.org/document/current/en/downloads/)
 
-> Scaling is an experimental feature, if scaling job fail, you could try nightly version, click here to [download nightly build]( https://github.com/apache/shardingsphere#nightly-builds ).
+2. Decompress the proxy release package and modify the configuration file `conf/config-sharding.yaml`. Please refer to [proxy startup guide](/en/user-manual/shardingsphere-proxy/startup/bin/) for details.
 
-2. Unzip the proxy distribution package, modify the configuration file `conf/config-sharding.yaml`. Please refer to [proxy startup manual](/en/user-manual/shardingsphere-proxy/startup/bin/) for more details.
+3. Modify the configuration file `conf/server.yaml`. Please refer to [mode configuration](/en/user-manual/shardingsphere-jdbc/yaml-config/mode/) for details.
 
-3. Modify the configuration file `conf/server.yaml`. Please refer to [Mode Configuration](/en/user-manual/shardingsphere-jdbc/yaml-config/mode/) for more details.
-Type of `mode` must be `Cluster` for now, please start the registry center before running proxy.
+Currently, `mode` must be `Cluster`, and the corresponding registry must be started in advance.
 
-Configuration Example:
+Configuration sample:
 ```yaml
 mode:
   type: Cluster
@@ -41,184 +49,136 @@ mode:
   overwrite: false
 ```
 
-4. Enable scaling
+4. Introduce JDBC driver.
 
-Way 1. Modify `scalingName` and `scaling` configuration in `conf/config-sharding.yaml`. 
+If the backend is connected to the following databases, download the corresponding JDBC driver jar package and put it into the `${shardingsphere-proxy}/lib` directory.
 
-Configuration Items Explanation:
-```yaml
-rules:
-- !SHARDING
-  # ignored configuration
-  
-  scalingName: # Enabled scaling action config name
-  scaling:
-    <scaling-action-config-name> (+):
-      input: # Data read configuration. If it's not configured, then part of its configuration will take effect.
-        workerThread: # Worker thread pool size for inventory data ingestion from source. If it's not configured, then use system default value.
-        batchSize: # Maximum records count of a DML select operation. If it's not configured, then use system default value.
-        rateLimiter: # Rate limit algorithm. If it's not configured, then system will skip rate limit.
-          type: # Algorithm type. Options: QPS
-          props: # Algorithm properties
-            qps: # QPS property. Available for types: QPS
-      output: # Data write configuration. If it's not configured, then part of its configuration will take effect.
-        workerThread: # Worker thread pool size for data importing to target. If it's not configured, then use system default value.
-        batchSize: # Maximum records count of a DML insert/delete/update operation. If it's not configured, then use system default value.
-        rateLimiter: # Rate limit algorithm. If it's not configured, then system will skip rate limit.
-          type: # Algorithm type. Options: TPS
-          props: # Algorithm properties
-            tps: # TPS property. Available for types: TPS
-      streamChannel: # Algorithm of channel that connect producer and consumer, used for input and output. If it's not configured, then system will use MEMORY type
-        type: # Algorithm type. Options: MEMORY
-        props: # Algorithm properties
-          block-queue-size: # Property: data channel block queue size. Available for types: MEMORY
-      completionDetector: # Completion detect algorithm. If it's not configured, then system won't continue to do next steps automatically.
-        type: # Algorithm type. Options: IDLE
-        props: # Algorithm properties
-          incremental-task-idle-seconds-threshold: # If incremental tasks is idle more than so much seconds, then it could be considered as almost completed. Available for types: IDLE
-      dataConsistencyChecker: # Data consistency check algorithm. If it's not configured, then system will skip this step.
-        type: # Algorithm type. Options: DATA_MATCH, CRC32_MATCH
-        props: # Algorithm properties
-          chunk-size: # Maximum records count of a query operation for check
+| Database              | JDBC Driver                                                                                                                                                        | Reference                                                                                        |
+| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------ |
+| MySQL                 | [mysql-connector-java-5.1.47.jar]( https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar )                              | [Connector/J Versions]( https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-versions.html ) |
+| openGauss             | [opengauss-jdbc-2.0.1-compatibility.jar]( https://repo1.maven.org/maven2/org/opengauss/opengauss-jdbc/2.0.1-compatibility/opengauss-jdbc-2.0.1-compatibility.jar ) |                                                                                                  |
+
+5. Start ShardingSphere-Proxy:
+
+```
+sh bin/start.sh
 ```
 
-`type` of `dataConsistencyChecker` could be got by executing DistSQL `SHOW SCALING CHECK ALGORITHMS`. Simple comparison:
-- `DATA_MATCH` : Support all types of databases, but it's not the best performant one.
-- `CRC32_MATCH` : Support `MySQL`, performance is better than `DATA_MATCH`.
+6. View the proxy log `logs/stdout.log`. If you see the following statements:
 
-Auto Mode Configuration Example:
-```yaml
-rules:
-- !SHARDING
-  # ignored configuration
-  
-  scalingName: scaling_auto
-  scaling:
-    scaling_auto:
-      input:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: QPS
-          props:
-            qps: 50
-      output:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: TPS
-          props:
-            tps: 2000
-      streamChannel:
-        type: MEMORY
-        props:
-          block-queue-size: 10000
-      completionDetector:
-        type: IDLE
-        props:
-          incremental-task-idle-seconds-threshold: 1800
-      dataConsistencyChecker:
-        type: DATA_MATCH
-        props:
-          chunk-size: 1000
+```
+[INFO ] [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy start success
 ```
 
-Manual Mode Configuration Example:
-```yaml
-rules:
-- !SHARDING
-  # ignored configuration
-  
-  scalingName: scaling_manual
-  scaling:
-    scaling_manual:
-      input:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: QPS
-          props:
-            qps: 50
-      output:
-        workerThread: 40
-        batchSize: 1000
-        rateLimiter:
-          type: TPS
-          props:
-            tps: 2000
-      streamChannel:
-        type: MEMORY
-        props:
-          block-queue-size: 10000
-      dataConsistencyChecker:
-        type: DATA_MATCH
-        props:
-          chunk-size: 1000
+The startup will have been successful.
+
+7. Configure and migrate on demand.
+
+7.1. Query configuration.
+
+```sql
+SHOW MIGRATION PROCESS CONFIGURATION;
+```
+
+The default configuration is as follows.
+
+```sql
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
+| read                                                         | write                                | stream_channel                                       |
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
+| {"workerThread":40,"batchSize":1000,"shardingSize":10000000} | {"workerThread":40,"batchSize":1000} | {"type":"MEMORY","props":{"block-queue-size":10000}} |
++--------------------------------------------------------------+--------------------------------------+------------------------------------------------------+
 ```
 
-Way 2: Configure scaling by DistSQL
+7.2. New configuration (Optional).
+
+A default value is available if there is no configuration.
+
+A completely configured DistSQL is as follows.
 
-Auto Mode Configuration Example:
 ```sql
-CREATE SHARDING SCALING RULE scaling_auto (
-INPUT(
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ(
   WORKER_THREAD=40,
   BATCH_SIZE=1000,
-  RATE_LIMITER(TYPE(NAME=QPS, PROPERTIES("qps"=50)))
+  SHARDING_SIZE=10000000,
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='500')))
 ),
-OUTPUT(
+WRITE(
   WORKER_THREAD=40,
   BATCH_SIZE=1000,
-  RATE_LIMITER(TYPE(NAME=TPS, PROPERTIES("tps"=2000)))
+  RATE_LIMITER (TYPE(NAME='TPS',PROPERTIES('tps'='2000')))
 ),
-STREAM_CHANNEL(TYPE(NAME="MEMORY", PROPERTIES("block-queue-size"="10000"))),
-COMPLETION_DETECTOR(TYPE(NAME="IDLE", PROPERTIES("incremental-task-idle-seconds-threshold"="1800"))),
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="DATA_MATCH", PROPERTIES("chunk-size"="1000")))
+STREAM_CHANNEL (TYPE(NAME='MEMORY',PROPERTIES('block-queue-size'='10000')))
 );
 ```
 
-Manual Mode Configuration Example:
+Configuration item description:
+
 ```sql
-CREATE SHARDING SCALING RULE scaling_manual (
-INPUT(
-  WORKER_THREAD=40,
-  BATCH_SIZE=1000
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ( -- Data reading configuration. If it is not configured, part of the parameters will take effect by default.
+  WORKER_THREAD=40, -- Obtain the thread pool size of all the data from the source side. If it is not configured, the default value is used.
+  BATCH_SIZE=1000, -- The maximum number of records returned by a query operation. If it is not configured, the default value is used.
+  SHARDING_SIZE=10000000, -- Sharding size of all the data. If it is not configured, the default value is used.
+  RATE_LIMITER ( -- Traffic limit algorithm. If it is not configured, traffic is not limited.
+  TYPE( -- Algorithm type. Option: QPS
+  NAME='QPS',
+  PROPERTIES( -- Algorithm property
+  'qps'='500'
+  )))
 ),
-OUTPUT(
-  WORKER_THREAD=40,
-  BATCH_SIZE=1000
+WRITE( -- Data writing configuration. If it is not configured, part of the parameters will take effect by default.
+  WORKER_THREAD=40, -- The size of the thread pool on which data is written into the target side. If it is not configured, the default value is used.
+  BATCH_SIZE=1000, -- The maximum number of records for a batch write operation. If it is not configured, the default value is used.
+  RATE_LIMITER ( -- Traffic limit algorithm. If it is not configured, traffic is not limited.
+  TYPE( -- Algorithm type. Option: TPS
+  NAME='TPS',
+  PROPERTIES( -- Algorithm property.
+  'tps'='2000'
+  )))
 ),
-STREAM_CHANNEL(TYPE(NAME="MEMORY", PROPERTIES("block-queue-size"="10000"))),
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="DATA_MATCH", PROPERTIES("chunk-size"="1000")))
+STREAM_CHANNEL ( -- Data channel. It connects producers and consumers, used for reading and writing procedures. If it is not configured, the MEMORY type is used by default.
+TYPE( -- Algorithm type. Option: MEMORY
+NAME='MEMORY',
+PROPERTIES( -- Algorithm property
+'block-queue-size'='10000' -- Property: blocking queue size.
+)))
 );
 ```
 
-Please refer to [RDL#Sharding](/en/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/) for more details.
-
-5. Import JDBC driver dependency
+DistSQL sample: configure `READ` for traffic limit.
 
-If the backend database is in following table, please download JDBC driver jar and put it into `${shardingsphere-proxy}/lib` directory.
-
-| RDBMS                 | JDBC driver                          | Reference            |
-| --------------------- | ------------------------------------ | -------------------- |
-| MySQL                 | [mysql-connector-java-5.1.47.jar]( https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar ) | [Connector/J Versions]( https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-versions.html ) |
-
-6. Start up ShardingSphere-Proxy:
-
-```
-sh bin/start.sh
+```sql
+CREATE MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='500')))
+)
+);
 ```
 
-7. Check proxy log `logs/stdout.log`:
+Configure data reading for traffic limit. Other configurations use default values.
 
-```
-[INFO ] [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy start success
-```
+7.3. Modify configuration.
 
-It means `proxy` start up successfully.
+`ALTER MIGRATION PROCESS CONFIGURATION`, and its internal structure is the same as that of `CREATE MIGRATION PROCESS CONFIGURATION`.
 
-## Shutdown
+DistSQL sample: modify traffic limit parameter
 
+```sql
+ALTER MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+)
+);
+---
+ALTER MIGRATION PROCESS CONFIGURATION (
+READ(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+), WRITE(
+  RATE_LIMITER (TYPE(NAME='QPS',PROPERTIES('qps'='1000')))
+)
+);
 ```
-sh bin/stop.sh
-```
+
+DistSQL sample: clear the configuration of `READ` and restore it to the default value.
diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.cn.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.cn.md
index 04830e9fbee..edd981fb441 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.cn.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.cn.md
@@ -3,39 +3,18 @@ title = "使用手册"
 weight = 2
 +++
 
-## 使用手册
+## MySQL使用手册
 
 ### 环境要求
 
-纯  JAVA 开发，JDK  建议 1.8 以上版本。
-
-支持的数据库及版本如下：
-
-| 源端                   | 目标端                   |
-| --------------------- | ----------------------- |
-| MySQL(5.1.15 ~ 5.7.x) | MySQL(5.1.15 ~ 5.7.x)   |
-| PostgreSQL(9.4 ~ )    | PostgreSQL(9.4 ~ )      |
-| openGauss(2.1.0)      | openGauss(2.1.0)        |
-
-功能支持情况：
-
-| 功能                   | MySQL         | PostgreSQL   | openGauss     |
-| --------------------- | ------------- |--------------| ------------- |
-| 全量迁移               | 支持           | 支持           | 支持           |
-| 增量迁移               | 支持           | 支持           | 支持           |
-| 自动建表               | 支持           | 支持           | 支持            |
-| DATA_MATCH一致性校验   | 支持           | 支持           | 支持           |
-| CRC32_MATCH一致性校验  | 支持           | 不支持          | 不支持          |
-
-**注意**：
-
-还没开启 `自动建表` 的数据库需要手动创建分表。
+支持的MySQL版本：5.1.15 ~ 5.7.x。
 
 ### 权限要求
-#### MySQL
+
 1. 开启 `binlog`
 
 MySQL 5.7 `my.cnf` 示例配置：
+
 ```
 [mysqld]
 server-id=1
@@ -46,12 +25,14 @@ max_connections=600
 ```
 
 执行以下命令，确认是否有开启 binlog：
+
 ```
 show variables like '%log_bin%';
 show variables like '%binlog%';
 ```
 
 如以下显示，则说明 binlog 已开启
+
 ```
 +-----------------------------------------+---------------------------------------+
 | Variable_name                           | Value                                 |
@@ -65,11 +46,13 @@ show variables like '%binlog%';
 2. 赋予 MySQL 账号 Replication 相关权限。
 
 执行以下命令，查看该用户是否有迁移权限：
+
 ```
 SHOW GRANTS FOR 'user';
 ```
 
 示例结果：
+
 ```
 +------------------------------------------------------------------------------+
 |Grants for ${username}@${host}                                                |
@@ -79,418 +62,498 @@ SHOW GRANTS FOR 'user';
 +------------------------------------------------------------------------------+
 ```
 
-#### PostgreSQL
+### 完整流程示例
 
-1. 开启 [test_decoding](https://www.postgresql.org/docs/9.4/test-decoding.html)。
+#### 前提条件
 
-2. 调整 WAL 配置。
+1. 在 MySQL 已准备好源端库、表、数据。
 
-`postgresql.conf` 示例配置：
-```
-wal_level = logical
-max_replication_slots = 10
-max_connections = 600
-```
+示例：
 
-详情请参见 [Write Ahead Log](https://www.postgresql.org/docs/9.6/runtime-config-wal.html) 和 [Replication](https://www.postgresql.org/docs/9.6/runtime-config-replication.html )。
+```sql
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0 DEFAULT CHARSET utf8;
+
+USE migration_ds_0
 
-### DistSQL 自动模式接口
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
+
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
+```
 
-#### 预览当前分片规则
+2. 在 MySQL 准备目标端库。
 
 示例：
+
 ```sql
-preview SELECT COUNT(1) FROM t_order;
-```
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10 DEFAULT CHARSET utf8;
 
-返回信息：
-```
-mysql> preview SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_0             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_1             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-2 rows in set (0.65 sec)
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11 DEFAULT CHARSET utf8;
+
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12 DEFAULT CHARSET utf8;
 ```
 
-#### 创建迁移任务
+#### 操作步骤
 
-1. 添加新的数据源。
+1. 在 proxy 新建逻辑数据库并配置好资源和规则。
 
-详情请参见 [RDL #数据源资源](/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/resource-definition/)。
+```sql
+CREATE DATABASE sharding_db;
 
-先在底层数据库系统创建需要的分库，下面的 `DistSQL` 需要用到。
+USE sharding_db
 
-示例：
-```sql
 ADD RESOURCE ds_2 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_2?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_10?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_3 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_3?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_11?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_4 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_4?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_12?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
-```
-
-2. 修改待迁移表的分片规则。
-
-待迁移表可以是所有表，也可以是部分表。绑定表只能一块迁移。
-
-目前只有通过执行 `ALTER SHARDING TABLE RULE` DistSQL 来触发迁移。
-
-详情请参见 [RDL #数据分片](/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/)。
-
-`SHARDING TABLE RULE` 支持 2 种类型：`TableRule` 和 `AutoTableRule`。以下是两种分片规则的对比：
-
-| 类型         | AutoTableRule（自动分片）                                      | TableRule（自定义分片）                                        |
-| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
-| 定义         | [自动化分片算法](/cn/features/sharding/concept/sharding/#自动化分片算法) | [自定义分片算法](/cn/features/sharding/concept/sharding/#自定义分片算法)   |
 
-DistSQL 字段含义和 YAML 配置保持一致，详情请参见 [YAML 配置#数据分片](/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/)。
-
-`AutoTableRule` 修改示例：
-```sql
-ALTER SHARDING TABLE RULE t_order (
-RESOURCES(ds_2, ds_3, ds_4),
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
 SHARDING_COLUMN=order_id,
 TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
 KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-`RESOURCES` 从 `(ds_0, ds_1)` 改为了 `(ds_2, ds_3, ds_4)`，`sharding-count` 从 `4` 改为了 `6`，会触发迁移。
+如果是迁移到异构数据库，那目前需要在 proxy 执行建表语句。
 
-`TableRule` 修改示例：
-```sql
-ALTER SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 3 + 2}"))
-);
+2. 在 proxy 配置源端资源。
 
-ALTER SHARDING TABLE RULE t_order (
-DATANODES("ds_${2..4}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${2..4}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
+```sql
+ADD MIGRATION SOURCE RESOURCE ds_0 (
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_0?serverTimezone=UTC&useSSL=false",
+    USER="root",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
 ```
 
-`database_inline` 的 `algorithm-expression` 从 `ds_${user_id % 2}` 改为 `ds_${user_id % 3 + 2}`，`t_order` 的 `DATANODES` 从 `ds_${0..1}.t_order_${0..1}` 改为 `ds_${2..4}.t_order_${0..1}`，会触发迁移。
+3. 启动数据迁移。
 
-目前 `ALTER SHARDING ALGORITHM` 会即时生效、但是规则还没生效，可能会导致源端 insert 异常，所以建议优先修改为 `AutoTableRule`。
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
+```
 
-#### 查询所有迁移任务
+或者指定目标端逻辑库：
 
-详情请参见 [RAL #弹性伸缩](/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/#%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9)。
+```sql
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
+```
+
+4. 查看数据迁移作业列表。
 
-示例：
 ```sql
 SHOW MIGRATION LIST;
 ```
 
-返回信息：
-```
-mysql> SHOW MIGRATION LIST;
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-| id                 | tables                | sharding_total_count | active | create_time         | stop_time           |
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-| 659853312085983232 | t_order_item, t_order | 2                    | false  | 2021-10-26 20:21:31 | 2021-10-26 20:24:01 |
-| 660152090995195904 | t_order_item, t_order | 2                    | false  | 2021-10-27 16:08:43 | 2021-10-27 16:11:00 |
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-2 rows in set (0.04 sec)
+示例结果：
+
+```sql
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
 ```
 
-#### 查询迁移任务进度
+5. 查看数据迁移详情。
 
-示例：
 ```sql
-SHOW MIGRATION STATUS {jobId};
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
 ```
 
-返回信息：
-```
-mysql> SHOW MIGRATION STATUS 660152090995195904;
-+------+-------------+----------+-------------------------------+--------------------------+
-| item | data_source | status   | inventory_finished_percentage | incremental_idle_seconds |
-+------+-------------+----------+-------------------------------+--------------------------+
-| 0    | ds_1        | FINISHED | 100                           | 2834                     |
-| 1    | ds_0        | FINISHED | 100                           | 2834                     |
-+------+-------------+----------+-------------------------------+--------------------------+
-2 rows in set (0.00 sec)
+6. 执行数据一致性校验。
+
+```sql
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='CRC32_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
-当前迁移任务已完成，新的分片规则已生效。如果迁移失败，新的分片规则不会生效。
 
-`status` 的取值：
+7. 停止作业。
 
-| 取值                                               | 描述                                                         |
-| ------------------------------------------------- | ------------------------------------------------------------ |
-| PREPARING                                         | 准备中                                                        |
-| RUNNING                                           | 运行中                                                        |
-| EXECUTE_INVENTORY_TASK                            | 全量迁移中                                                     |
-| EXECUTE_INCREMENTAL_TASK                          | 增量迁移中                                                     |
-| FINISHED                                          | 已完成（整个流程完成了，新规则已生效）                              |
-| PREPARING_FAILURE                                 | 准备阶段失败                                                    |
-| EXECUTE_INVENTORY_TASK_FAILURE                    | 全量迁移阶段失败                                                 |
-| EXECUTE_INCREMENTAL_TASK_FAILURE                  | 增量迁移阶段失败                                                 |
+```sql
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
+```
 
-如果 `status` 出现失败的情况，可以查看 `proxy` 的日志查看错误堆栈分析问题。
+8. 清理作业。
 
-#### 预览新的分片规则是否生效
+```sql
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
+```
+
+9. 刷新元数据。
 
-示例：
 ```sql
-preview SELECT COUNT(1) FROM t_order;
+REFRESH TABLE METADATA;
 ```
 
-返回信息：
+## PostgreSQL使用手册
+
+### 环境要求
+
+支持的PostgreSQL版本：9.4 或以上版本。
+
+### 权限要求
+
+1. 开启 [test_decoding](https://www.postgresql.org/docs/9.4/test-decoding.html)。
+
+2. 调整 WAL 配置。
+
+`postgresql.conf` 示例配置：
 ```
-mysql> preview SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_2             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_3             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_4             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-3 rows in set (0.21 sec)
+wal_level = logical
+max_wal_senders = 10
+max_replication_slots = 10
+max_connections = 600
 ```
 
-#### 其他 DistSQL
-详情请参见 [RAL #弹性伸缩](/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/#%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9)。
+详情请参见 [Write Ahead Log](https://www.postgresql.org/docs/9.6/runtime-config-wal.html) 和 [Replication](https://www.postgresql.org/docs/9.6/runtime-config-replication.html )。
 
-### DistSQL 手动模式完整流程示例
+3. 配置 PostgreSQL 允许 Proxy 拥有 replication 权限。
 
-手动模式下，数据校验、切换配置等操作可以手动执行。详情请参见：[RAL #弹性伸缩](/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/#%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9)。
+pg_hba.conf实例配置：
+host replication repl_acct 0.0.0.0/0 md5
 
-本示例演示从已有 MySQL 数据库迁移到 proxy。
+详情请参见 [The pg_hba.conf File](https://www.postgresql.org/docs/9.6/auth-pg-hba-conf.html)。
 
-除了明确说明在 MySQL 执行的 SQL，其他都是在 proxy 执行。
+### 完整流程示例
 
-#### 新建源端库
+#### 前提条件
 
-已有数据不需要这个步骤。这里是模拟一个源端库用于测试。
+1. 在 PostgreSQL 已准备好源端库、表、数据。
 
-在 MySQL 执行 SQL：
 ```sql
-DROP DATABASE IF EXISTS scaling_ds_0;
-CREATE DATABASE scaling_ds_0 DEFAULT CHARSET utf8;
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0;
 
-DROP DATABASE IF EXISTS scaling_ds_1;
-CREATE DATABASE scaling_ds_1 DEFAULT CHARSET utf8;
-```
+\c migration_ds_0
 
-#### 登录 proxy
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
 
-```shell
-mysql -h127.0.0.1 -P3307 -uroot -proot
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
 ```
 
-#### 创建并配置逻辑库
+2. 在 PostgreSQL 准备目标端库。
 
-创建逻辑库：
 ```sql
-CREATE DATABASE scaling_db;
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10;
 
-USE scaling_db
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11;
+
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12;
 ```
 
-加入源端数据库资源：
+#### 操作步骤
+
+1. 在 proxy 新建逻辑数据库并配置好资源和规则。
+
 ```sql
-ADD RESOURCE ds_0 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_0?serverTimezone=UTC&useSSL=false",
-    USER="root",
+CREATE DATABASE sharding_db;
+
+\c sharding_db
+
+ADD RESOURCE ds_2 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_10",
+    USER="postgres",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
-), ds_1 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_1?serverTimezone=UTC&useSSL=false",
-    USER="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+), ds_3 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_11",
+    USER="postgres",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+), ds_4 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_12",
+    USER="postgres",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+);
+
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
+SHARDING_COLUMN=order_id,
+TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
+KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-配置规则：
-把现有系统中的表配置到规则里，使用 tables 规则 INLINE 算法，方便适配已有的表名。
+如果是迁移到异构数据库，那目前需要在 proxy 执行建表语句。
+
+2. 在 proxy 配置源端资源。
+
 ```sql
-CREATE SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 2}"))
-);
-CREATE SHARDING ALGORITHM t_order_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="t_order_${order_id % 2}"))
-);
-CREATE SHARDING ALGORITHM t_order_item_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="t_order_item_${order_id % 2}"))
+ADD MIGRATION SOURCE RESOURCE ds_0 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_0",
+    USER="postgres",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
+```
 
-CREATE SHARDING TABLE RULE t_order (
-DATANODES("ds_${0..1}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${0..1}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
-);
+3. 启动数据迁移。
 
-CREATE SHARDING SCALING RULE scaling_manual2 (
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="CRC32_MATCH"))
-);
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
 ```
 
-#### 创建测试表并初始化数据
+或者指定目标端逻辑库：
+
+```sql
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
+```
 
-该步骤在实际使用中不需要。
+4. 查看数据迁移作业列表。
 
 ```sql
-CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) CHARSET utf8mb4, PRIMARY KEY (order_id));
-CREATE TABLE t_order_item (item_id INT NOT NULL, order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) CHARSET utf8mb4, creation_date DATE, PRIMARY KEY (item_id));
+SHOW MIGRATION LIST;
+```
 
-INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
-INSERT INTO t_order_item (item_id, order_id, user_id, status) VALUES (1,1,2,'ok'),(2,2,4,'ok'),(3,3,6,'ok'),(4,4,1,'ok'),(5,5,3,'ok'),(6,6,5,'ok');
+示例结果：
+
+```sql
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+```
+
+5. 查看数据迁移详情。
+
+```sql
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+```
+
+6. 执行数据一致性校验。
+
+```sql
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='DATA_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
 
-#### 执行迁移
+7. 停止作业。
 
-预览分片：
 ```sql
-mysql> PREVIEW SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_0             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_1             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-2 rows in set (0.65 sec)
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
 
-在 MySQL 创建目标端库：
+8. 清理作业。
+
 ```sql
-DROP DATABASE IF EXISTS scaling_ds_10;
-CREATE DATABASE scaling_ds_10 DEFAULT CHARSET utf8;
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
+```
 
-DROP DATABASE IF EXISTS scaling_ds_11;
-CREATE DATABASE scaling_ds_11 DEFAULT CHARSET utf8;
+9. 刷新元数据。
 
-DROP DATABASE IF EXISTS scaling_ds_12;
-CREATE DATABASE scaling_ds_12 DEFAULT CHARSET utf8;
+```sql
+REFRESH TABLE METADATA;
 ```
 
-加入目标端数据库资源：
+## openGauss使用手册
+
+### 环境要求
+
+支持的openGauss版本：2.0.1 ~ 3.0.0。
+
+### 权限要求
+
+1. 调整 WAL 配置。
+
+`postgresql.conf` 示例配置：
+```
+wal_level = logical
+max_wal_senders = 10
+max_replication_slots = 10
+wal_sender_timeout = 0
+max_connections = 600
+```
+
+详情请参见 [Write Ahead Log](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/settings.html) 和 [Replication](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/sending-server.html)。
+
+2. 配置 PostgreSQL 允许 Proxy 拥有 replication 权限。
+
+pg_hba.conf实例配置：
+host replication repl_acct 0.0.0.0/0 md5
+
+详情请参见 [Configuring Client Access Authentication](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/configuring-client-access-authentication.html) 和 [Example: Logic Replication Code](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/example-logic-replication-code.html)。
+
+### 完整流程示例
+
+#### 前提条件
+
+1. 在 openGauss 已准备好源端库、表、数据。
+
 ```sql
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0;
+
+\c migration_ds_0
+
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
+
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
+```
+
+2. 在 openGauss 准备目标端库。
+
+```sql
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10;
+
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11;
+
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12;
+```
+
+#### 操作步骤
+
+1. 在 proxy 新建逻辑数据库并配置好资源和规则。
+
+```sql
+CREATE DATABASE sharding_db;
+
+\c sharding_db
+
 ADD RESOURCE ds_2 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_10?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_10",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_3 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_11?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_11",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_4 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_12?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_12",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+);
+
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
+SHARDING_COLUMN=order_id,
+TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
+KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-修改分片规则触发迁移：
+如果是迁移到异构数据库，那目前需要在 proxy 执行建表语句。
+
+2. 在 proxy 配置源端资源。
+
 ```sql
-ALTER SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 3 + 2}"))
+ADD MIGRATION SOURCE RESOURCE ds_2 (
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_0",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
+```
 
-ALTER SHARDING TABLE RULE t_order (
-DATANODES("ds_${2..4}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${2..4}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
-);
+3. 启动数据迁移。
+
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
+```
+
+或者指定目标端逻辑库：
+
+```sql
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
+```
+
+4. 查看数据迁移作业列表。
+
+```sql
+SHOW MIGRATION LIST;
 ```
 
-查看当前迁移任务的进度：
+示例结果：
+
 ```sql
-mysql> SHOW MIGRATION LIST;
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-| id                                         | tables               | sharding_total_count | active | create_time         | stop_time |
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-| 0130317c30317c3054317c7363616c696e675f6462 | t_order,t_order_item | 2                    | true   | 2022-04-16 17:22:19 | NULL      |
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-1 row in set (0.34 sec)
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+```
+
+5. 查看数据迁移详情。
 
-mysql> SHOW MIGRATION STATUS "0130317c30317c3054317c7363616c696e675f6462";
+```sql
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
 +------+-------------+--------------------------+--------+-------------------------------+--------------------------+
 | item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
 +------+-------------+--------------------------+--------+-------------------------------+--------------------------+
-| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 8                        |
-| 1    | ds_1        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 7                        |
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
 +------+-------------+--------------------------+--------+-------------------------------+--------------------------+
-2 rows in set (0.02 sec)
 ```
-当 status 达到 EXECUTE_INCREMENTAL_TASK，全量迁移已完成，在增量迁移阶段。
-
 
-选择一个业务低峰期，对源端库或数据操作入口做停写。
+6. 执行数据一致性校验。
 
-proxy 停写：
 ```sql
-mysql> STOP MIGRATION SOURCE WRITING "0130317c30317c3054317c7363616c696e675f6462";
-Query OK, 0 rows affected (0.07 sec)
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='DATA_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
 
-数据一致性校验：
+7. 停止作业。
+
 ```sql
-mysql> CHECK MIGRATION "0130317c30317c3054317c7363616c696e675f6462" BY TYPE (NAME="CRC32_MATCH");
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-| table_name   | source_records_count | target_records_count | records_count_matched | records_content_matched |
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-| t_order      | 6                    | 6                    | true                  | true                    |
-| t_order_item | 6                    | 6                    | true                  | true                    |
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-2 rows in set (2.16 sec)
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
 
-切换元数据：
+8. 清理作业。
+
 ```sql
-mysql> APPLY MIGRATION "0130317c30317c3054317c7363616c696e675f6462";
-Query OK, 0 rows affected (0.22 sec)
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
 
-预览分片是否已生效：
+9. 刷新元数据。
+
 ```sql
-mysql> PREVIEW SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_2             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_3             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_4             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-3 rows in set (0.21 sec)
+REFRESH TABLE METADATA;
 ```
-数据已经分片到新的数据库资源。
-
-可选择性删除不再使用的 ds_0 和 ds_1。
diff --git a/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.en.md b/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.en.md
index 29538aa7233..ed0cc134d99 100644
--- a/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.en.md
+++ b/docs/document/content/user-manual/shardingsphere-proxy/scaling/usage.en.md
@@ -3,41 +3,18 @@ title = "Manual"
 weight = 2
 +++
 
-## Manual
+## MySQL user guide
 
 ### Environment
 
-JAVA, JDK 1.8+.
+Supported MySQL versions: 5.1.15 to 5.7.x.
 
-The migration scene we support:
-
-| Source                     | Target                  |
-| -------------------------- | ----------------------- |
-| MySQL(5.1.15 ~ 5.7.x)      | MySQL(5.1.15 ~ 5.7.x)   |
-| PostgreSQL(9.4 ~ )         | PostgreSQL(9.4 ~ )      |
-| openGauss(2.1.0)           | openGauss(2.1.0)        |
-
-Supported features:
-
-| Feature                                  | MySQL         | PostgreSQL    | openGauss     |
-| ---------------------------------------- | ------------- |---------------| ------------- |
-| Inventory migration                      | Supported     | Supported     | Supported     |
-| Incremental migration                    | Supported     | Supported     | Supported     |
-| Create table automatically               | Supported     | Supported     | Supported     |
-| DATA_MATCH data consistency check        | Supported     | Supported     | Supported     |
-| CRC32_MATCH data consistency check       | Supported     | Unsupported   | Unsupported   |
-
-**Attention**:
-
-For RDBMS which `Create table automatically` feature is not supported, we need to create sharding tables manually.
-
-### Privileges
-
-#### MySQL
+### Authority required
 
 1. Enable `binlog`
 
-Configuration Example of MySQL 5.7 `my.cnf`:
+MySQL 5.7 `my.cnf` configuration sample:
+
 ```
 [mysqld]
 server-id=1
@@ -47,13 +24,13 @@ binlog-row-image=full
 max_connections=600
 ```
 
-Execute the following SQL to confirm whether binlog is turned on or not:
-```sql
+Run the following command and check whether `binlog` is enabled.
+```
 show variables like '%log_bin%';
 show variables like '%binlog%';
 ```
 
-As shown below, it means binlog has been turned on:
+If the following information is displayed, binlog is enabled.
 ```
 +-----------------------------------------+---------------------------------------+
 | Variable_name                           | Value                                 |
@@ -64,14 +41,14 @@ As shown below, it means binlog has been turned on:
 +-----------------------------------------+---------------------------------------+
 ```
 
-2. Privileges of account that scaling use should include Replication privileges.
+2. Grant Replication-related permissions for MySQL account.
 
-Execute the following SQL to confirm whether the user has migration permission or not:
-```sql
+Run the following command and see whether the user has migration permission.
+```
 SHOW GRANTS FOR 'user';
 ```
 
-Result Example:
+Result sample: 
 ```
 +------------------------------------------------------------------------------+
 |Grants for ${username}@${host}                                                |
@@ -81,417 +58,486 @@ Result Example:
 +------------------------------------------------------------------------------+
 ```
 
-#### PostgreSQL
+### Complete procedure example
 
-1. Enable [test_decoding](https://www.postgresql.org/docs/9.4/test-decoding.html) feature.
+#### Prerequisite
 
-2. Adjust WAL configuration
+1. Prepare the source database, table, and data in MySQL.
 
-Configuration Example of `postgresql.conf`:
-```
-wal_level = logical
-max_replication_slots = 10
-max_connections = 600
-```
+Sample: 
 
-Please refer to [Write Ahead Log](https://www.postgresql.org/docs/9.6/runtime-config-wal.html) and [Replication](https://www.postgresql.org/docs/9.6/runtime-config-replication.html ) for more details.
+```sql
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0 DEFAULT CHARSET utf8;
 
-### DistSQL API for auto mode
+USE migration_ds_0
 
-#### Preview current sharding rule
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
 
-Example:
-```sql
-preview SELECT COUNT(1) FROM t_order;
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
 ```
 
-Response:
-```
-mysql> preview SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_0             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_1             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-2 rows in set (0.65 sec)
-```
+2. Prepare the target database in MySQL.
+
+Sample: 
+
+```sql
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10 DEFAULT CHARSET utf8;
 
-#### Start scaling job
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11 DEFAULT CHARSET utf8;
 
-1. Add new data source resources
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12 DEFAULT CHARSET utf8;
+```
 
-Please refer to [RDL#Data Source](/en/user-manual/shardingsphere-proxy/distsql/syntax/rdl/resource-definition/) for more details.
+#### Procedure
 
-Create database on underlying RDBMS first, it will be used in following `DistSQL`.
+1. Create a new logical database in proxy and configure resources and rules.
 
-Example:
 ```sql
+CREATE DATABASE sharding_db;
+
+USE sharding_db
+
 ADD RESOURCE ds_2 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_2?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_10?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_3 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_3?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_11?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_4 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_4?serverTimezone=UTC&useSSL=false",
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_12?serverTimezone=UTC&useSSL=false",
     USER="root",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="10","idleTimeout"="30000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
-```
-
-2. Alter sharding table rule for tables to be scaled
-
-We could scale all tables or partial tables. Binding tables must be scaled together.
 
-Currently, scaling job could only be emitted by executing `ALTER SHARDING TABLE RULE` DistSQL.
-
-Please refer to [RDL#Sharding](/en/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/) for more details.
-
-`SHARDING TABLE RULE` support two types: `TableRule` and `AutoTableRule`. Following is a comparison of the two sharding rule types: 
-
-| Type         | AutoTableRule                                               | TableRule                                                    |
-| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
-| Definition   | [Auto Sharding Algorithm](/en/features/sharding/concept/sharding/#auto-sharding-algorithm) | [User-Defined Sharding Algorithm](/en/features/sharding/concept/sharding/#user-defined-sharding-algorithm)   |
-
-Meaning of fields in DistSQL is the same as YAML configuration, please refer to [YAML Configuration#Sharding](/en/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/) for more details.
-
-Example of alter `AutoTableRule`:
-```sql
-ALTER SHARDING TABLE RULE t_order (
-RESOURCES(ds_2, ds_3, ds_4),
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
 SHARDING_COLUMN=order_id,
 TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
 KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-`RESOURCES` is altered from `(ds_0, ds_1)` to `(ds_2, ds_3, ds_4)`, and `sharding-count` is altered from `4` to `6`, it will emit scaling job.
+If you are migrating to a heterogeneous database, you need to execute the table-creation statements in proxy.
 
-Uncompleted example of alter `TableRule`:
-```sql
-ALTER SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 3 + 2}"))
-);
+2. Configure the source resources in proxy.
 
-ALTER SHARDING TABLE RULE t_order (
-DATANODES("ds_${2..4}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${2..4}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
+```sql
+ADD MIGRATION SOURCE RESOURCE ds_0 (
+    URL="jdbc:mysql://127.0.0.1:3306/migration_ds_0?serverTimezone=UTC&useSSL=false",
+    USER="root",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
 ```
 
-`algorithm-expression` of `database_inline` is alerted from `ds_${user_id % 2}` to `ds_${user_id % 3 + 2}`, and `DATANODES` of `t_order` is alerted from `ds_${0..1}.t_order_${0..1}` to `ds_${2..4}.t_order_${0..1}`, it will emit scaling job.
+3. Start data migration.
 
-Currently, `ALTER SHARDING ALGORITHM` will take effect immediately, but table rule will not, it might cause inserting data into source side failure, so alter sharding table rule to `AutoTableRule` is recommended for now.
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
+```
+
+Or you can specify a target logical database.
 
-#### List scaling jobs
+```sql
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
+```
 
-Please refer to [RAL#Scaling](/en/user-manual/shardingsphere-proxy/distsql/syntax/ral/#scaling) for more details.
+4. Check the data migration job list.
 
-Example:
 ```sql
 SHOW MIGRATION LIST;
 ```
 
-Response:
+Result example:
+
+```sql
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
 ```
-mysql> SHOW MIGRATION LIST;
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-| id                 | tables                | sharding_total_count | active | create_time         | stop_time           |
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-| 659853312085983232 | t_order_item, t_order | 2                    | false  | 2021-10-26 20:21:31 | 2021-10-26 20:24:01 |
-| 660152090995195904 | t_order_item, t_order | 2                    | false  | 2021-10-27 16:08:43 | 2021-10-27 16:11:00 |
-+--------------------+-----------------------+----------------------+--------+---------------------+---------------------+
-2 rows in set (0.04 sec)
+
+5. View the data migration details.
+
+```sql
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
 ```
 
-#### Get migration progress
+6. Verify data consistency.
 
-Example:
 ```sql
-SHOW MIGRATION STATUS {jobId};
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='DATA_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
 
-Response:
+7. Stop the job.
+
+```sql
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
-mysql> SHOW MIGRATION STATUS 660152090995195904;
-+------+-------------+----------+-------------------------------+--------------------------+
-| item | data_source | status   | inventory_finished_percentage | incremental_idle_seconds |
-+------+-------------+----------+-------------------------------+--------------------------+
-| 0    | ds_1        | FINISHED | 100                           | 2834                     |
-| 1    | ds_0        | FINISHED | 100                           | 2834                     |
-+------+-------------+----------+-------------------------------+--------------------------+
-2 rows in set (0.00 sec)
+
+8. Clear the job.
+
+```sql
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
-Current scaling job is finished, new sharding rule should take effect, and not if scaling job is failed.
 
-`status` values:
+## PostgreSQL user guide
 
-| Value                                             | Description                                                  |
-| ------------------------------------------------- | ------------------------------------------------------------ |
-| PREPARING                                         | preparing                                                    |
-| RUNNING                                           | running                                                      |
-| EXECUTE_INVENTORY_TASK                            | inventory task running                                       |
-| EXECUTE_INCREMENTAL_TASK                          | incremental task running                                     |
-| FINISHED                                          | finished (The whole process is completed, and the new rules have been taken effect) |
-| PREPARING_FAILURE                                 | preparation failed                                           |
-| EXECUTE_INVENTORY_TASK_FAILURE                    | inventory task failed                                        |
-| EXECUTE_INCREMENTAL_TASK_FAILURE                  | incremental task failed                                      |
+### Environment
 
-If `status` fails, you can check the log of `proxy` to view the error stack and analyze the problem.
+Supported PostgreSQL version: 9.4 or later.
 
-#### Preview new sharding rule
+### Authority required
 
-Example:
-```sql
-preview SELECT COUNT(1) FROM t_order;
-```
+1. Enable [test_decoding](https://www.postgresql.org/docs/9.4/test-decoding.html).
+
+2. Modify WAL Configuration.
 
-Response:
+`postgresql.conf` configuration sample: 
 ```
-mysql> PREVIEW SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_2             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_3             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_4             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-3 rows in set (0.21 sec)
+wal_level = logical
+max_wal_senders = 10
+max_replication_slots = 10
+max_connections = 600
 ```
 
-#### Other DistSQL
-Please refer to [RAL#Scaling](/en/user-manual/shardingsphere-proxy/distsql/syntax/ral/#scaling) for more details.
+Please refer to [Write Ahead Log](https://www.postgresql.org/docs/9.6/runtime-config-wal.html) and [Replication](https://www.postgresql.org/docs/9.6/runtime-config-replication.html ) for details.
+
+3. Configure PostgreSQL and grant Proxy the replication permission.
 
-### DistSQL manual mode whole process example
+`pg_hba.conf` instance configuration: 
 
-On manual mode, data consistency check and switch configuration could be emitted manually. Please refer to [RAL#Scaling](/en/user-manual/shardingsphere-proxy/distsql/syntax/ral/#scaling) for more details.
+```sql
+host replication repl_acct 0.0.0.0/0 md5
+```
 
-This example show how to migrate data from MySQL to proxy.
+Please refer to [The pg_hba.conf File](https://www.postgresql.org/docs/9.6/auth-pg-hba-conf.html) for details.
 
-Most SQLs should be executed in proxy, except few ones mentioned for MySQL.
+### Complete procedure example
 
-#### Create source databases
+#### Prerequisite
 
-It's not needed in practice. It just simulates databases for testing.
+1. Prepare the source database, table, and data in PostgreSQL.
 
-Execute SQLs in MySQL:
 ```sql
-DROP DATABASE IF EXISTS scaling_ds_0;
-CREATE DATABASE scaling_ds_0 DEFAULT CHARSET utf8;
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0;
 
-DROP DATABASE IF EXISTS scaling_ds_1;
-CREATE DATABASE scaling_ds_1 DEFAULT CHARSET utf8;
-```
+\c migration_ds_0
 
-#### Login proxy
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
 
-```shell
-mysql -h127.0.0.1 -P3307 -uroot -proot
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
 ```
 
-#### Create and configure logical database
+2. Prepare the target database in PostgreSQL.
 
-Create logical database:
 ```sql
-CREATE DATABASE scaling_db;
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10;
 
-USE scaling_db
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11;
+
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12;
 ```
 
-Add source database resource:
+#### Procedure
+
+1. Create a new logical database in proxy and configure resources and rules.
+
 ```sql
-ADD RESOURCE ds_0 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_0?serverTimezone=UTC&useSSL=false",
-    USER="root",
+CREATE DATABASE sharding_db;
+
+\c sharding_db
+
+ADD RESOURCE ds_2 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_10",
+    USER="postgres",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
-), ds_1 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_1?serverTimezone=UTC&useSSL=false",
-    USER="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+), ds_3 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_11",
+    USER="postgres",
     PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+), ds_4 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_12",
+    USER="postgres",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+);
+
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
+SHARDING_COLUMN=order_id,
+TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
+KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-Configure rules:
-Configure tables of existing system in sharding rule, sharding table rules and INLINE algorithm will be used to fit existing tables name.
+If you are migrating to a heterogeneous database, you need to execute the table-creation statements in proxy.
+
+2. Configure the source resources in proxy.
+
 ```sql
-CREATE SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 2}"))
-);
-CREATE SHARDING ALGORITHM t_order_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="t_order_${order_id % 2}"))
-);
-CREATE SHARDING ALGORITHM t_order_item_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="t_order_item_${order_id % 2}"))
+ADD MIGRATION SOURCE RESOURCE ds_0 (
+    URL="jdbc:postgresql://127.0.0.1:5432/migration_ds_0",
+    USER="postgres",
+    PASSWORD="root",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
+```
 
-CREATE SHARDING TABLE RULE t_order (
-DATANODES("ds_${0..1}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${0..1}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
-);
+3. Enable data migration.
 
-CREATE SHARDING SCALING RULE scaling_manual2 (
-DATA_CONSISTENCY_CHECKER(TYPE(NAME="CRC32_MATCH"))
-);
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
+```
+
+Or you can specify a target logical database.
+
+```sql
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
 ```
 
-#### Create test tables and initialize records
+4. Check the data migration job list.
+
+```sql
+SHOW MIGRATION LIST;
+```
+
+Result sample: 
+
+```sql
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+```
 
-It's not needed in practice.
+5. View the data migration details.
 
 ```sql
-CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) CHARSET utf8mb4, PRIMARY KEY (order_id));
-CREATE TABLE t_order_item (item_id INT NOT NULL, order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) CHARSET utf8mb4, creation_date DATE, PRIMARY KEY (item_id));
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+```
+
+6. Verify data consistency.
 
-INSERT INTO T_ORDER (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
-INSERT INTO T_ORDER_ITEM (item_id, order_id, user_id, status) VALUES (1,1,2,'ok'),(2,2,4,'ok'),(3,3,6,'ok'),(4,4,1,'ok'),(5,5,3,'ok'),(6,6,5,'ok');
+```sql
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='DATA_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
 
-#### Run migration
+7. Stop the job.
 
-Preview sharding:
 ```sql
-mysql> PREVIEW SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_0             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_1             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-2 rows in set (0.65 sec)
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
 
-Create target databases in MySQL:
+8. Clear the job.
+
 ```sql
-DROP DATABASE IF EXISTS scaling_ds_10;
-CREATE DATABASE scaling_ds_10 DEFAULT CHARSET utf8;
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
+```
+
+## openGauss user guide
 
-DROP DATABASE IF EXISTS scaling_ds_11;
-CREATE DATABASE scaling_ds_11 DEFAULT CHARSET utf8;
+### Environment
+
+Supported openGauss version: 2.0.1 to 3.0.0.
+
+### Authority required
+
+1. Modify WAL configuration.
+
+`postgresql.conf` configuration sample:
+```
+wal_level = logical
+max_wal_senders = 10
+max_replication_slots = 10
+wal_sender_timeout = 0
+max_connections = 600
+```
+
+Please refer to [Write Ahead Log](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/settings.html) and [Replication](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/sending-server.html) for details.
+
+2. Configure PostgreSQL and grant Proxy the replication permission.
 
-DROP DATABASE IF EXISTS scaling_ds_12;
-CREATE DATABASE scaling_ds_12 DEFAULT CHARSET utf8;
+`pg_hba.conf` instance configuration: 
+
+```sql
+host replication repl_acct 0.0.0.0/0 md5
 ```
 
-Add target database resource:
+Please refer to [Configuring Client Access Authentication](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/configuring-client-access-authentication.html) and [Example: Logic Replication Code](https://opengauss.org/en/docs/2.0.1/docs/Developerguide/example-logic-replication-code.html) for details.
+
+### Complete procedure example
+
+#### Prerequisite
+
+1. Prepare the source database, table, and data in openGauss.
+
 ```sql
+DROP DATABASE IF EXISTS migration_ds_0;
+CREATE DATABASE migration_ds_0;
+
+\c migration_ds_0
+
+CREATE TABLE t_order (order_id INT NOT NULL, user_id INT NOT NULL, status VARCHAR(45) NULL, PRIMARY KEY (order_id));
+
+INSERT INTO t_order (order_id, user_id, status) VALUES (1,2,'ok'),(2,4,'ok'),(3,6,'ok'),(4,1,'ok'),(5,3,'ok'),(6,5,'ok');
+```
+
+2. Prepare the target database in openGauss.
+
+```sql
+DROP DATABASE IF EXISTS migration_ds_10;
+CREATE DATABASE migration_ds_10;
+
+DROP DATABASE IF EXISTS migration_ds_11;
+CREATE DATABASE migration_ds_11;
+
+DROP DATABASE IF EXISTS migration_ds_12;
+CREATE DATABASE migration_ds_12;
+```
+
+#### Procedure
+
+1. Create a new logical database and configure resources and rules.
+
+```sql
+CREATE DATABASE sharding_db;
+
+\c sharding_db
+
 ADD RESOURCE ds_2 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_10?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_10",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_3 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_11?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_11",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 ), ds_4 (
-    URL="jdbc:mysql://127.0.0.1:3306/scaling_ds_12?serverTimezone=UTC&useSSL=false",
-    USER="root",
-    PASSWORD="root",
-    PROPERTIES("maximumPoolSize"="50","idleTimeout"="60000")
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_12",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
+);
+
+CREATE SHARDING TABLE RULE t_order(
+RESOURCES(ds_2,ds_3,ds_4),
+SHARDING_COLUMN=order_id,
+TYPE(NAME="hash_mod",PROPERTIES("sharding-count"="6")),
+KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
 );
 ```
 
-Alter sharding rule to emit scaling job:
+If you are migrating to a heterogeneous database, you need to execute the table-creation statements in proxy.
+
+2. Configure the source resources in proxy.
+
 ```sql
-ALTER SHARDING ALGORITHM database_inline (
-TYPE(NAME="INLINE",PROPERTIES("algorithm-expression"="ds_${user_id % 3 + 2}"))
+ADD MIGRATION SOURCE RESOURCE ds_2 (
+    URL="jdbc:opengauss://127.0.0.1:5432/migration_ds_0",
+    USER="gaussdb",
+    PASSWORD="Root@123",
+    PROPERTIES("minPoolSize"="1","maxPoolSize"="20","idleTimeout"="60000")
 );
+```
 
-ALTER SHARDING TABLE RULE t_order (
-DATANODES("ds_${2..4}.t_order_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME="snowflake"))
-), t_order_item (
-DATANODES("ds_${2..4}.t_order_item_${0..1}"),
-DATABASE_STRATEGY(TYPE="standard",SHARDING_COLUMN=user_id,SHARDING_ALGORITHM=database_inline),
-TABLE_STRATEGY(TYPE="standard",SHARDING_COLUMN=order_id,SHARDING_ALGORITHM=t_order_item_inline),
-KEY_GENERATE_STRATEGY(COLUMN=order_item_id,TYPE(NAME="snowflake"))
-);
+3. Enable data migration.
+
+```sql
+MIGRATE TABLE ds_0.t_order INTO t_order;
 ```
 
-Query job progress:
+Or you can specify a target logical database.
+
 ```sql
-mysql> SHOW MIGRATION LIST;
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-| id                                         | tables               | sharding_total_count | active | create_time         | stop_time |
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-| 0130317c30317c3054317c7363616c696e675f6462 | t_order,t_order_item | 2                    | true   | 2022-04-16 17:22:19 | NULL      |
-+--------------------------------------------+----------------------+----------------------+--------+---------------------+-----------+
-1 row in set (0.34 sec)
+MIGRATE TABLE ds_0.t_order INTO sharding_db.t_order;
+```
 
-mysql> SHOW MIGRATION STATUS "0130317c30317c3054317c7363616c696e675f6462";
-+------+-------------+--------------------------+--------+-------------------------------+--------------------------+
-| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
-+------+-------------+--------------------------+--------+-------------------------------+--------------------------+
-| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 8                        |
-| 1    | ds_1        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 7                        |
-+------+-------------+--------------------------+--------+-------------------------------+--------------------------+
-2 rows in set (0.02 sec)
+4. Check the data migration job list.
+
+```sql
+SHOW MIGRATION LIST;
 ```
-When `status` is `EXECUTE_INCREMENTAL_TASK`, it means inventory migration stage is successful, it's running on incremental migration stage.
 
-Choose an idle time of business system, stop source database writing or stop upper database operation.
+Result example: 
 
-Stop source writing in proxy:
 ```sql
-mysql> STOP MIGRATION SOURCE WRITING "0130317c30317c3054317c7363616c696e675f6462";
-Query OK, 0 rows affected (0.07 sec)
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| id                                  | tables  | sharding_total_count | active | create_time         | stop_time |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
+| j015d4ee1b8a5e7f95df19babb2794395e8 | t_order | 1                    | true   | 2022-08-22 16:37:01 | NULL      |
++-------------------------------------+---------+----------------------+--------+---------------------+-----------+
 ```
 
-Data consistency check:
+5. View the data migration details.
+
 ```sql
-mysql> CHECK MIGRATION "0130317c30317c3054317c7363616c696e675f6462" BY TYPE (NAME="CRC32_MATCH");
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-| table_name   | source_records_count | target_records_count | records_count_matched | records_content_matched |
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-| t_order      | 6                    | 6                    | true                  | true                    |
-| t_order_item | 6                    | 6                    | true                  | true                    |
-+--------------+----------------------+----------------------+-----------------------+-------------------------+
-2 rows in set (2.16 sec)
+SHOW MIGRATION STATUS 'j015d4ee1b8a5e7f95df19babb2794395e8';
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| item | data_source | status                   | active | inventory_finished_percentage | incremental_idle_seconds |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
+| 0    | ds_0        | EXECUTE_INCREMENTAL_TASK | true   | 100                           | 141                      |
++------+-------------+--------------------------+--------+-------------------------------+--------------------------+
 ```
 
-Apply metadata:
+6. Verify data consistency.
+
 ```sql
-mysql> APPLY MIGRATION "0130317c30317c3054317c7363616c696e675f6462";
-Query OK, 0 rows affected (0.22 sec)
+CHECK MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8' BY TYPE (NAME='DATA_MATCH');
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| table_name | source_records_count | target_records_count | records_count_matched | records_content_matched |
++------------+----------------------+----------------------+-----------------------+-------------------------+
+| t_order    | 6                    | 6                    | true                  | true                    |
++------------+----------------------+----------------------+-----------------------+-------------------------+
 ```
 
-Preview sharding again:
+7. Stop the job.
+
 ```sql
-mysql> PREVIEW SELECT COUNT(1) FROM t_order;
-+------------------+-------------------------------------------------------------------------+
-| data_source_name | actual_sql                                                              |
-+------------------+-------------------------------------------------------------------------+
-| ds_2             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_3             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-| ds_4             | SELECT COUNT(1) FROM t_order_0 UNION ALL SELECT COUNT(1) FROM t_order_1 |
-+------------------+-------------------------------------------------------------------------+
-3 rows in set (0.21 sec)
+STOP MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
 ```
-Sharding already take effect.
 
-Optionally, unused `ds_0` and `ds_1` could be removed.
+8. Clear the job.
+
+```
+CLEAN MIGRATION 'j015d4ee1b8a5e7f95df19babb2794395e8';
+```
