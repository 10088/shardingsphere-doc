commit 899992ca574a57708a752ce678235f27a76f82ba
Author: Liang Zhang <terrymanu@163.com>
Date:   Mon Oct 18 07:29:03 2021 +0800

    Sync Chinese document with English document (#13079)
    
    * Update solution
    
    * Update brackets
    
    * Update readme
    
    * Sync chinese document with english
    
    * Update readme
    
    * Sync Chinese document with English document
    
    * Update space
    
    * Sync Chinese document with English document
    
    * Sync Chinese document with English document

diff --git a/docs/blog/content/material/result.en.md b/docs/blog/content/material/result.en.md
index b56df00c7d..09cec9f6f4 100644
--- a/docs/blog/content/material/result.en.md
+++ b/docs/blog/content/material/result.en.md
@@ -36,19 +36,14 @@ It is the simplest form of aggregation. Simply merge multiple result sets into a
 
 Due to the existence of the ORDER BY statement in SQL, each data result set is itself ordered, so only the data values that the current cursor of the data result set points to need to be sorted. This is equivalent to sorting multiple ordered arrays, and merge sorting is the most appropriate sorting algorithm for this scenario.
 
-
-
 Sharding-Sphere compares the current data values of each result set (done by implementing Java's Comparable interface) and places them in a priority queue when the sorted queries are merged. Each time the next piece of data is fetched, simply move the cursor of the result set at the top of the queue down and find your place in the priority queue again based on the new cursor. To illustrate Sharding-Sphere's sorting and merging with an example, the following diagram shows an example of sorting by score.
- 
 
 ![](https://shardingsphere.apache.org/blog/img/result1.jpg)
 
-
 The example shows 3 tables returning data result sets, each of which is already sorted according to score, but is unordered between the 3 data result sets. The data values pointed to by the current cursor for each of the 3 result sets are sorted and placed into a priority queue, with the first data value of t_score_0 being the largest, the first data value of t_score_2 the next largest, and the first data value of t_score_1 the smallest, so the priority queue is based on the t_score_0, t_score_2, and t_score_1's The following diagram shows how sorting the queue is done when the next call is made.
 
 The following diagram shows how the sorting and merging is done when the next call is made.
 
-
 ![](https://shardingsphere.apache.org/blog/img/result2.jpg)
  
 As we can see from the diagram, when the first NEXT call is made, t_score_0, which is at the top of the queue, is ejected from the queue and returns the data value (i.e., 100) that the current cursor points to to the querying client, and is placed back into the priority queue after moving the cursor down one place. The priority queue is also ranked according to the data value (in this case 90) that the current result set of t_score_0 points to for the cursor, with t_score_0 ranked last in the queue according to the current value. The result set of t_score_2, which was previously ranked second in the queue, is automatically ranked first in the queue.
@@ -71,27 +66,23 @@ To illustrate, suppose that the table structure contains the candidate's name (d
  
 In the case where the grouping item is identical to the sorting item, the data obtained is continuous, and the full amount of data required for grouping exists in the data values pointed to by the current cursor of each data result set, so streamwise merging can be used. This is shown in the figure below.
 
-
 ![](https://shardingsphere.apache.org/blog/img/result4.jpg)
  
 When performing a merge, the logic is similar to a sorted merge. The following diagram shows how stream group merging is performed when next call is made.
 
 ![](https://shardingsphere.apache.org/blog/img/result5.jpg)
 
- 
 As you can see in the diagram, when the first next call is made, the first t_score_java is ejected from the queue, along with all other result sets with the same value as "Jetty". After obtaining the scores of all students named "Jetty" and adding them up, the result set is the sum of "Jetty's" scores at the end of the first next call. At the same time, all cursors in the result set are moved down to the next different value of "Jetty" and re-sorted according to the value of the current cursor in the result set. As a result, the relevant result set containing the name "John" in the second place is at the top of the queue.
 
 Stream Group-by Merger merging differs from sorted merging in just two ways.
 
-1.	It will be a one-time multiple data result set of grouped items of the same data out of all.
-2.	It needs to be aggregated according to the type of aggregation function to calculate.
+1. It will be a one-time multiple data result set of grouped items of the same data out of all.
+2. It needs to be aggregated according to the type of aggregation function to calculate.
 
-For cases where the grouped item does not match the sorted item, since the data values associated with the grouping that needs to be obtained are not continuous, stream merging cannot be used and all the result set data needs to be loaded into memory for grouping and aggregation. For example, if the following SQL is used to obtain the total score for each candidate and sort the scores from highest to lowest.
- 
+For cases where the grouped item does not match the sorted item, since the data values associated with the grouping that needs to be obtained are not continuous, stream merging cannot be used and all the result set data needs to be loaded into memory for grouping and aggregation. For example, if the following SQL is used to obtain the total score for each candidate and sort the scores from highest to lowest. 
  
  ![](https://shardingsphere.apache.org/blog/img/result6.jpg)
- 
- 
+
 Then the data taken out of each data result set is consistent with the original data in the table structure in the upper half of the sorting example diagram for the scores, and it is not possible to perform streamwise summation.
 
 When the SQL contains only grouping statements, the order of sorting may not be the same as the grouping order depending on the implementation of different databases. However, the absence of the sorting statement means that this SQL does not care about the sorting order. Therefore, Sharding-Sphere automatically adds sorted items consistent with grouped items through SQL-optimized rewrites, allowing it to convert from a memory-consuming in-memory grouped imputation approach to a streaming grouped imputation scheme.
@@ -103,7 +94,6 @@ Sum and COUNT are aggregation functions that need to be added to the result set
 
 It must be calculated by the SQL rewrite of SUM and COUNT, the relevant content has been covered in the SQL rewrite, not to repeat.
 
-
 #### Pagination Merger
 
 Pagination is possible for all of the merge types described above. Pagination is a decorator appended on top of other merge types, and Sharding-Sphere adds the ability to paginate the result set of data through the decorator mode. The Pagination imputation is responsible for filtering out data that does not need to be fetched.
diff --git a/docs/blog/content/material/ss_5.0.0beta.cn.md b/docs/blog/content/material/ss_5.0.0beta.cn.md
index aacbd4b96b..98ce63820a 100644
--- a/docs/blog/content/material/ss_5.0.0beta.cn.md
+++ b/docs/blog/content/material/ss_5.0.0beta.cn.md
@@ -34,23 +34,22 @@ Original 潘娟 SphereEx 6/22
 ### 1. 亮点功能
 
 #### 全新定义的分布式数据库操作语言—DistSQL
-	
+
 SQL 是一种用于存取数据以及查询、更新和管理关系数据库系统的数据库查询和程序设计语言。1986 年 10 月，美国国家标准学会将 SQL 作为关系式数据库管理系统的标准语言。现有通用数据库系统在其实践过程中都对 SQL 规范作了部分改写和扩充，具有更高灵活性和更丰富的功能，使其适用于自身的数据库系统。
-	
+
 DistSQL（Distributed SQL）是 Apache ShardingSphere 提出的，特有的一种内置 SQL 语言，能够提供标准 SQL 之外的增量功能操作能力。DistSQL 让用户可以像操作数据库一样操作 ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的基础设施产品。
-	
+
 在 ShardingSphere 中， DistSQL 目前主要划分为 RDL、RQL 和 RAL 三种具体类型：
-	
+
 * RDL（Resource & Rule Definition Language）：资源和规则的创建、修改和删除；
 * RQL（Resource & Rule Query Language）：资源和规则的查询和展现； 
 * RAL（Resource & Rule Administration Language）：Hint、事务类型切换、分片执行计划查询等增量功能操作。
-	
+
 ShardingSphere 推出 Database Plus 理念，为传统数据库赋能，构建具备分布式、高安全、可管控等的数据库增强生态，打造兼具数据库且贴合实际业务需求的开源分布式数据库体系。与该分布式数据库体系搭配使用的分布式 SQL（Distributed SQL）将传统通过配置文件驱动的分布式数据库代理端 ShardingSphere-Proxy，变成真正意义上通过 SQL 驱动的“分布式数据库”。
-	
+
 在 5.0.0-beta 版本中，用户可一键启动 ShardingSphere-Proxy，并通过 DistSQL 在线动态创建、修改、删除分布式数据库表，加密数据库表，动态注入数据库实例资源，创建主从轮询规则，展示全局配置信息，开启分布式事务，启动动态迁移分布式库表作业等功能。
-	
-DistSQL 这种数据库态产品，让用户用最规范、标准、熟悉的查询方式操纵及管理 ShardingSphere 分布式数据库生态所有数据库资源及元数据信息。未来我们将通过 DistSQL 打破中间件和数据库之间的界限，让开发者真正像使用数据库一样原生的使用 ShardingSphere。
 
+DistSQL 这种数据库态产品，让用户用最规范、标准、熟悉的查询方式操纵及管理 ShardingSphere 分布式数据库生态所有数据库资源及元数据信息。未来我们将通过 DistSQL 打破中间件和数据库之间的界限，让开发者真正像使用数据库一样原生的使用 ShardingSphere。
 
 #### 全面对接 PostgreSQL 生态
 
@@ -60,7 +59,6 @@ ShardingSphere-JDBC 和 ShardingSphere-Proxy 共同构成 ShardingSphere 的接
 
 PostgreSQL 作为开源界的明星数据库产品，ShardingSphere 与 PostgreSQL 的链接，将为考虑将 PostgreSQL 分布式化、水平拓展化、安全加密化、细粒度权限控制化的用户提供更为完善和持续维护的解决方案。
 
-
 #### ShardingSphere 可插拔架构
 
 可插拔架构追求各个模块的相互独立和互无感知，并且通过一个高灵活度，可插拔和可扩展内核，以叠加的方式将各种功能组合使用。
@@ -117,7 +115,7 @@ ShardingSphere 在功能不断完善、新功能不断开发的进程中，一
 
 除了上述列举的功能外，本次发布还进行了其他方面的功能增强、性能优化、缺陷修复等处理。在后续的系列文章中，我们将会持续为大家带来 Apache ShardingSphere 5.0.0-beta 的正式发布报道、各个特性及功能的深度技术文章，欢迎锁定我们的系列更新！
 
-**🔗	ShardingSphere GitHub 地址：**
+**🔗 ShardingSphere GitHub 地址：**
 
 <https://github.com/apache/shardingsphere>
 
diff --git a/docs/blog/content/material/ss_5.0.0beta.en.md b/docs/blog/content/material/ss_5.0.0beta.en.md
index 27f1bad484..5c835c8c98 100644
--- a/docs/blog/content/material/ss_5.0.0beta.en.md
+++ b/docs/blog/content/material/ss_5.0.0beta.en.md
@@ -8,7 +8,7 @@ As an Apache top-level project, ShardingSphere goes through community verificati
 
 ## Release Features:
 
-### 1.	Highlight Features
+### 1. Highlight Features
 
 #### DistSQL – A New SQL Type for a Distributed Database Ecosystem
 
@@ -49,14 +49,14 @@ Currently data sharding, Readwrite-splitting, data encryption, Shadow databases,
 
 Pluggable architecture’s improvement effectively evolves ShardingSphere into a distributed database ecosystem. The pluggable and extensible concepts provide a customized combinational database solution that can be built upon with Lego-like blocks. For example, traditional relational databases can be scaled out and encrypted at the same time, while distributed database solutions can be built independently.
 
-### 2.	New Features
+### 2. New Features
 
 #### New Open Observability
 
 ShardingSphere provides automated probes to effectively separate observability from the main functionality. This brings significant convenience for user-customized tracing, metrics, and logging. 
 OpenTracing, Jaeger, Zipkin based tracing probes and Prometheus Metrics probes, as well as a default logging implementation also have built-in implementations.
 
-### 3.	Enhancements
+### 3. Enhancements
 
 #### Enhanced Distributed Query Capability
 
@@ -105,66 +105,66 @@ In addition to above mentioned features, for a comprehensive list of enhancement
 
 ### Other New Features:
 
-1.	New DistSQL for loading and presenting ShardingSphere’s configuration.
-2.	Support for join queries and sub-queries across different databased instances.
-3.	Data gateway is added to support heterogeneous databases.
-4.	Support create and modify user permission online or dynamically.
-5.	New automated probes module.
+1. New DistSQL for loading and presenting ShardingSphere’s configuration.
+2. Support for join queries and sub-queries across different databased instances.
+3. Data gateway is added to support heterogeneous databases.
+4. Support create and modify user permission online or dynamically.
+5. New automated probes module.
 
 ### API Changes:
 
-1.	API in read and write splitting module configuration changed to read-write-splitting.
-2.	API for ShardingProxy user permission configuration changed to Authority.
-3.	Using dataSourceClassName to optimize the dataSource configuration of ShardingJDBC.
-4.	Automated ShardingTable configuration strategy, provide standard built-in shard table.
-5.	Removed ShardingProxy acceptor-size configuration option.
-6.	Added built-in shard algorithm SPI so users can set up the shard algorithm through class name like in the version 4.x.
+1. API in read and write splitting module configuration changed to read-write-splitting.
+2. API for ShardingProxy user permission configuration changed to Authority.
+3. Using dataSourceClassName to optimize the dataSource configuration of ShardingJDBC.
+4. Automated ShardingTable configuration strategy, provide standard built-in shard table.
+5. Removed ShardingProxy acceptor-size configuration option.
+6. Added built-in shard algorithm SPI so users can set up the shard algorithm through class name like in the version 4.x.
 
 ### Enhancements:
 
-1.	Startup metadata loading performance has been significantly improved.
-2.	Greatly enhanced the parsing abilities for Oracle/SQLServer/PostgreSQL database.
-3.	Supporting initialization of the user permission MySQL/PostgreSQL/SQLServer/Oracle.
-4.	Supporting DDL language for data encryption.
-5.	When sharding and encryption are used together, SQL is supported for modifying the table named owner.
-6.	Using SELECT* to rewrite SQL, overwrite columns to add escape characters to avoid column conflicts with keywords.
-7.	Supporting PostgreSQL JSON/JSONB/ for pattern matching operator parsing.
-8.	Supporting MySQL/PostgreSQL CREATE/ALTER/DROP TABLESPACE.
-9.	Supporting PostgreSQL PREPARE, EXECUTE, DEALLOCATE.
-10.	Supporting PostgreSQL EXPLAIN.
-11.	Supporting PostgreSQL START/END TRANSACTION.
-12.	Supporting PostgreSQL ALTER/DROP INDEX.
-13.	Supporting PostgreSQL dialect CREATE TABLESPACE.
-14.	Supporting MySQL CREATE LOADABLE FUNCTION.
-15.	Supporting MySQL/PostgreSQL ALTER TABLE RENAME.
-16.	Supporting PostgreSQL protocol Close command.
+1. Startup metadata loading performance has been significantly improved.
+2. Greatly enhanced the parsing abilities for Oracle/SQLServer/PostgreSQL database.
+3. Supporting initialization of the user permission MySQL/PostgreSQL/SQLServer/Oracle.
+4. Supporting DDL language for data encryption.
+5. When sharding and encryption are used together, SQL is supported for modifying the table named owner.
+6. Using SELECT* to rewrite SQL, overwrite columns to add escape characters to avoid column conflicts with keywords.
+7. Supporting PostgreSQL JSON/JSONB/ for pattern matching operator parsing.
+8. Supporting MySQL/PostgreSQL CREATE/ALTER/DROP TABLESPACE.
+9. Supporting PostgreSQL PREPARE, EXECUTE, DEALLOCATE.
+10. Supporting PostgreSQL EXPLAIN.
+11. Supporting PostgreSQL START/END TRANSACTION.
+12. Supporting PostgreSQL ALTER/DROP INDEX.
+13. Supporting PostgreSQL dialect CREATE TABLESPACE.
+14. Supporting MySQL CREATE LOADABLE FUNCTION.
+15. Supporting MySQL/PostgreSQL ALTER TABLE RENAME.
+16. Supporting PostgreSQL protocol Close command.
 
 ### Changes:
 
-1.	New registry storage structure.
+1. New registry storage structure.
 2. Removed support for NACOS and Apollo's Configuration Centre.
 3. ShardingScaling introduces ElasticJob to handle migration tasks.
 4. Refactoring the storage and online update of the kernel metadata information.
 
 ### Bug fixes:
 
-1.	Fixed issue where SELECT * wildcard SQL could not be used for read/write separation.
-2.	The custom sharding algorithm did not match the configuration type and the class instance did not meet expectations issue is fixed.
-3.	Fixed the NoSuchTableException when executing DROP TABLE IF EXISTS.
-4.	Fixed UPDATE ... SET ... rewrite error.
-5.	Fixed CREATE/ALTER TABLE statement using foreign key to reference TABLE overwrite error.
-6.	Fixed the issue when querying subqueries in the temporal table field verification exception.
-7.	Fixed Oracle/SQL92 SELECT ... WHERE ... LIKE class cast exception.
-8.	Fixed MySQL SELECT EXISTS ... FROM ... parsing exception.
-9.	Fixed SHOW INDEX result exception.
-10.	Fixed the rewrite and merge result exception for SELECT... GROUP BY ...
-11.	Fixed the encryption and decryption error for CREATE TABLE rewrite.
-12.	Fixed issue with PostgreSQL Proxy reading text parameter values incorrectly.
-13.	Fixed PostgreSQL Proxy support for array objects.
-14.	Fixed ShardingProxy Datatype conversion issues.
-15.	PostgreSQL Proxy supports the use of the Numeric type.
-16.	Fixed the issue with incorrect Tag for PostgreSQL Proxy transactions related to Command Complete.
-17.	Fixed the issue that might return packets that were not expected by the client.
+1. Fixed issue where SELECT * wildcard SQL could not be used for read/write separation.
+2. The custom sharding algorithm did not match the configuration type and the class instance did not meet expectations issue is fixed.
+3. Fixed the NoSuchTableException when executing DROP TABLE IF EXISTS.
+4. Fixed UPDATE ... SET ... rewrite error.
+5. Fixed CREATE/ALTER TABLE statement using foreign key to reference TABLE overwrite error.
+6. Fixed the issue when querying subqueries in the temporal table field verification exception.
+7. Fixed Oracle/SQL92 SELECT ... WHERE ... LIKE class cast exception.
+8. Fixed MySQL SELECT EXISTS ... FROM ... parsing exception.
+9. Fixed SHOW INDEX result exception.
+10. Fixed the rewrite and merge result exception for SELECT... GROUP BY ...
+11. Fixed the encryption and decryption error for CREATE TABLE rewrite.
+12. Fixed issue with PostgreSQL Proxy reading text parameter values incorrectly.
+13. Fixed PostgreSQL Proxy support for array objects.
+14. Fixed ShardingProxy Datatype conversion issues.
+15. PostgreSQL Proxy supports the use of the Numeric type.
+16. Fixed the issue with incorrect Tag for PostgreSQL Proxy transactions related to Command Complete.
+17. Fixed the issue that might return packets that were not expected by the client.
 
 **Download Link:** <https://shardingsphere.apache.org/document/current/en/downloads/>
 
diff --git a/docs/community/content/contribute/establish-project.cn.md b/docs/community/content/contribute/establish-project.cn.md
index 46561dbed1..54f14ccd7e 100644
--- a/docs/community/content/contribute/establish-project.cn.md
+++ b/docs/community/content/contribute/establish-project.cn.md
@@ -10,8 +10,8 @@ chapter = true
 ## 安装步骤（ Mac 为例）
 ## 1.JDK 安装
 - 下方链接获取适合自己环境的安装包（ mac 选取 .dmg 格式）
--	https://www.oracle.com/java
-	![JDK.png](https://shardingsphere.apache.org/community/image/download_source/JDK.png)
+- https://www.oracle.com/java
+  ![JDK.png](https://shardingsphere.apache.org/community/image/download_source/JDK.png)
 - 下载完成后直接安装即可
 ## 2.设置环境变量
 ```shell
@@ -37,7 +37,7 @@ source ~/.zprofile
 ## 4.Idea clone 代码
 - 进入 Idea
 - 工具栏-->Git-->Clone-->Url(https://github.com/apache/shardingsphere.git)
-	![Idea.png](https://shardingsphere.apache.org/community/image/download_source/Idea.png)
+ ![Idea.png](https://shardingsphere.apache.org/community/image/download_source/Idea.png)
 - 等待结束就有刚刚克隆的最新的代码了
 ## 5.项目编译
 ```shell
diff --git a/docs/community/content/contribute/establish-project.en.md b/docs/community/content/contribute/establish-project.en.md
index 791426d3f7..8be8b869ae 100644
--- a/docs/community/content/contribute/establish-project.en.md
+++ b/docs/community/content/contribute/establish-project.en.md
@@ -10,8 +10,8 @@ chapter = true
 ## Installation Procedure (For example, Mac)
 ## 1.The JDK installation
 - The following link is to obtain the installation package suitable for your environment (MAC select.dmg format).
--	https://www.oracle.com/java
-	![JDK.png](https://shardingsphere.apache.org/community/image/download_source/JDK.png)
+- https://www.oracle.com/java
+ ![JDK.png](https://shardingsphere.apache.org/community/image/download_source/JDK.png)
 - Install it directly after downloading
 ## 2.Set the environment variable
 ```shell
@@ -32,12 +32,12 @@ source ~/.zprofile
 ```
 ## 3.Idea Download and install
 - The following link provides an installation package suitable for your environment
-	https://www.jetbrains.com/idea/download/#section=mac
+ https://www.jetbrains.com/idea/download/#section=mac
 - Install it directly after downloading
 ## 4.Idea clone code
 - Enter Idea
 - Toolbar-->Git-->Clone-->Url(https://github.com/apache/shardingsphere.git)
-	![Idea.png](https://shardingsphere.apache.org/community/image/download_source/Idea.png)
+ ![Idea.png](https://shardingsphere.apache.org/community/image/download_source/Idea.png)
 - At the end of the wait, there is the latest code that has just been cloned
 ## 5.Compile the project
 ```shell
diff --git a/docs/document/content/overview/_index.cn.md b/docs/document/content/overview/_index.cn.md
index c0616279ce..0a4d607b37 100644
--- a/docs/document/content/overview/_index.cn.md
+++ b/docs/document/content/overview/_index.cn.md
@@ -25,7 +25,7 @@ Apache ShardingSphere 产品定位为 `Database Plus`，旨在构建多模数据
 
 - `连接`：通过对数据库协议、SQL 方言以及数据库存储的灵活适配，快速的连接应用与多模式的异构数据库；
 - `增量`：获取数据库的访问流量，并提供流量重定向（数据分片、读写分离、影子库）、流量变形（数据加密、数据脱敏）、流量鉴权（安全、审计、权限）、流量治理（熔断、限流）以及流量分析（服务质量分析、可观察性）等透明化增量功能；
-- `可插拔`：项目采用微内核 + 3 层可插拔模型，使内核、功能组件以及生态对接完全能够灵活的方式进行插拔式扩展，开发者能够像使用积木一样定制属于自己的独特系统。
+- `可插拔`：项目采用微内核 + 三层可插拔模型，使内核、功能组件以及生态对接完全能够灵活的方式进行插拔式扩展，开发者能够像使用积木一样定制属于自己的独特系统。
 
 ShardingSphere 已于2020年4月16日成为 [Apache 软件基金会](https://apache.org/index.html#projects-list)的顶级项目。
 欢迎通过[邮件列表](mailto:dev@shardingsphere.apache.org)参与讨论。
@@ -111,30 +111,13 @@ Apache ShardingSphere 是多接入端共同组成的生态圈。
 
 ## 解决方案
 
-### 分布式数据库
-
-* 数据分片
-* 读写分离
-* 分布式事务
-* 弹性伸缩
-* 分布式高可用
-
-### 数据安全
-
-* 数据加密
-* 行级权限（TODO）
-* SQL 审计（TODO）
-* SQL 防火墙（TODO）
-
-### 数据库网关
-
-* 异构数据库支持
-* SQL 方言转换（TODO）
-
-### 全链路压测
-
-* 影子库
-* 可观测性（分布式跟踪、指标度量）
+| *解决方案/功能* |  *分布式数据库* | *数据安全*        | *数据库网关*        | *全链路压测* |
+| ------------- | ------------- | ----------------| ----------------- | ---------- |
+|               | 数据分片       | 数据加密          | 异构数据库支持       | 影子库     |
+|               | 读写分离       | 行级权限（TODO）   | SQL 方言转换（TODO）| 可观测性    |
+|               | 分布式事务     | SQL 审计（TODO）   |                   |           |
+|               | 弹性伸缩       | SQL 防火墙（TODO） |                   |           |
+|               | 高可用        |                   |                   |           |
 
 ## 线路规划
 
diff --git a/docs/document/content/overview/_index.en.md b/docs/document/content/overview/_index.en.md
index 0a8163e57d..a052341fd6 100644
--- a/docs/document/content/overview/_index.en.md
+++ b/docs/document/content/overview/_index.en.md
@@ -18,15 +18,14 @@ chapter = true
 
 [![Contributors Over Time](https://contributor-graph-api.apiseven.com/contributors-svg?chart=contributorOverTime&repo=apache/shardingsphere)](https://www.apiseven.com/en/contributor-graph?chart=contributorOverTime&repo=apache/shardingsphere)
 
-Apache ShardingSphere is positioned as `Database Plus`, which aims to build criterion and ecosystem above multi-model databases.
-It focuses on how to reuse existing database, rather than creating a new database.
-ShardingSphere focuses on the upper layer of databases, pays more attention on cooperation between databases rather than database itself.
+Apache ShardingSphere is positioned as a Database Plus, and aims at building a new criterion and ecosystem above multi-model databases. 
+It focuses on how to reuse existing databases and their respective upper layer, rather than creating a new database.
 
-`Link`, `Enhance` and `Pluggable` is the core concepts of Apache ShardingSphere.
+The concepts at the core of the project are Link, Enhance and Pluggable.
 
-- `Link`：Flexible adaptation of database protocol, SQL dialect and database storage, it can link applications and multi-mode heterogeneous databases quickly;
-- `Enhance`：Capture database access entry to provide additional features transparently, such as: redirect (sharding, readwrite-splitting and shadow), transform (data encrypt and mask), authentication (security, audit and authority), governance（circuit breaker and access limitation and analyse (Qos and observability);
-- `Pluggable`：Use micro kernel and 3 layers pluggable mode, to make features and database ecosystem can be embedded flexibility. Developers can customize their ShardingSphere just like building blocks.
+- `Link:` Flexible adaptation of database protocol, SQL dialect and database storage. It can quickly link applications and multi-mode heterogeneous databases quickly.
+- `Enhance:` Capture database access entry to provide additional features transparently, such as: redirect (sharding, readwrite-splitting and shadow), transform (data encrypt and mask), authentication (security, audit and authority), governance (circuit breaker and access limitation and analyze, QoS and observability).
+- `Pluggable:` Leveraging the micro kernel and 3 layers pluggable mode, features and database ecosystem can be embedded flexibily. Developers can customize their ShardingSphere just like building with LEGO blocks.
 
 ShardingSphere became an [Apache](https://apache.org/index.html#projects-list) Top-Level Project on April 16, 2020.
 
@@ -118,30 +117,13 @@ Architects can adjust the system architecture to the most applicable one to thei
 
 ## Solution
 
-### Distributed Database
-
-* Data Sharding
-* Readwrite-splitting
-* Distributed Transaction
-* Elastic Scale-out
-* Distributed Highly Available
-
-### Data Security
-
-* Data Encrypt
-* Row Authority (TODO)
-* SQL Audit (TODO)
-* SQL Firewall (TODO)
-
-### Database Gateway
-
-* Multi-model Databases supported
-* SQL Dialect Translate（TODO）
-
-### Stress Testing
-
-* Shadow Database
-* Observability (Tracing and Metrics)
+| *Solutions/Features* |  *Distributed Database* | *Data Security*      | *Database Gateway*              | *Stress Testing* |
+| -------------------- | ----------------------- | ---------------------| ------------------------------- | ---------------- |
+|                      | Data Sharding           | Data Encrypt         | Multi-model Databases Supported | Shadow Database  |
+|                      | Readwrite-splitting     | Row Authority (TODO) | SQL Dialect Translate (TODO)    | Observability    |
+|                      | Distributed Transaction | SQL Audit (TODO)     |                                 |                  |
+|                      | Elastic Scale-out       | SQL Firewall (TODO)  |                                 |                  |
+|                      | Highly Available        |                      |                                 |                  |
 
 ## Roadmap
 
diff --git a/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.cn.md b/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.cn.md
index 69a4ceb651..8ec65d7f98 100644
--- a/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.cn.md
+++ b/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.cn.md
@@ -30,7 +30,6 @@ weight = 6
                            http://shardingsphere.apache.org/schema/shardingsphere/encrypt
                            http://shardingsphere.apache.org/schema/shardingsphere/encrypt/encrypt.xsd
                            ">
-						   
     <bean id="write_ds0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <property name="driverClassName" value="com.mysql.jdbc.Driver" />
         <property name="jdbcUrl" value="jdbc:mysql://localhost:3306/write_ds?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8" />
@@ -46,29 +45,29 @@ weight = 6
         <!-- 省略详细数据源配置详情 -->
     </bean>
     
-	<bean id="write_ds1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
+    <bean id="write_ds1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- 省略详细数据源配置详情 -->
     </bean>
-	
-	<bean id="read_ds1_0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
+    
+    <bean id="read_ds1_0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- 省略详细数据源配置详情 -->
     </bean>
     
     <bean id="read_ds1_1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- 省略详细数据源配置详情 -->
     </bean>
-	
-	<!-- 主从配置负载均衡策略 -->
+    
+    <!-- 主从配置负载均衡策略 -->
     <readwrite-splitting:load-balance-algorithm id="randomStrategy" type="RANDOM" />
     
-	<!-- 主从规则配置 -->
+    <!-- 主从规则配置 -->
     <readwrite-splitting:rule id="readWriteSplittingRule">
         <readwrite-splitting:data-source-rule id="ds_0" write-data-source-name="write_ds0" read-data-source-names="read_ds0_0, read_ds0_1" load-balance-algorithm-ref="randomStrategy" />
-		<readwrite-splitting:data-source-rule id="ds_1" write-data-source-name="write_ds1" read-data-source-names="read_ds1_0, read_ds1_1" load-balance-algorithm-ref="randomStrategy" />
+        <readwrite-splitting:data-source-rule id="ds_1" write-data-source-name="write_ds1" read-data-source-names="read_ds1_0, read_ds1_1" load-balance-algorithm-ref="randomStrategy" />
     </readwrite-splitting:rule>
     
-	<!-- 分片策略配置 -->
-	<sharding:standard-strategy id="databaseStrategy" sharding-column="user_id" algorithm-ref="inlineDatabaseStrategyAlgorithm" />
+    <!-- 分片策略配置 -->
+    <sharding:standard-strategy id="databaseStrategy" sharding-column="user_id" algorithm-ref="inlineDatabaseStrategyAlgorithm" />
     <sharding:standard-strategy id="orderTableStrategy" sharding-column="order_id" algorithm-ref="inlineOrderTableStrategyAlgorithm" />
     <sharding:standard-strategy id="orderItemTableStrategy" sharding-column="order_item_id" algorithm-ref="inlineOrderItemTableStrategyAlgorithm" />
 
@@ -119,8 +118,8 @@ weight = 6
         </encrypt:table>
     </encrypt:rule>
     
-	<!-- 数据源配置 -->
-	<!-- data-source-names 数据源名称为所有的数据源节点名称 -->
+    <!-- 数据源配置 -->
+    <!-- data-source-names 数据源名称为所有的数据源节点名称 -->
     <shardingsphere:data-source id="readQueryDataSource" data-source-names="write_ds0, read_ds0_0, read_ds0_1, write_ds1, read_ds1_0, read_ds1_1" 
         rule-refs="readWriteSplittingRule, shardingRule, encryptRule" >
         <props>
diff --git a/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.en.md b/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.en.md
index 1fde361101..b04e2706b8 100644
--- a/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.en.md
+++ b/docs/document/content/user-manual/shardingsphere-jdbc/configuration/spring-namespace/mix.en.md
@@ -25,7 +25,6 @@ weight = 6
                            http://shardingsphere.apache.org/schema/shardingsphere/encrypt
                            http://shardingsphere.apache.org/schema/shardingsphere/encrypt/encrypt.xsd
                            ">
-						   
     <bean id="write_ds0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <property name="driverClassName" value="com.mysql.jdbc.Driver" />
         <property name="jdbcUrl" value="jdbc:mysql://localhost:3306/write_ds?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8" />
@@ -41,29 +40,29 @@ weight = 6
         <!-- ...Omit specific configuration. -->
     </bean>
     
-	<bean id="write_ds1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
+    <bean id="write_ds1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- ...Omit specific configuration. -->
     </bean>
-	
-	<bean id="read_ds1_0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
+    
+    <bean id="read_ds1_0" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- ...Omit specific configuration. -->
     </bean>
     
     <bean id="read_ds1_1" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close">
         <!-- ...Omit specific configuration. -->
     </bean>
-	
-	<!-- load balance algorithm configuration for readwrite-splitting -->
+    
+    <!-- load balance algorithm configuration for readwrite-splitting -->
     <readwrite-splitting:load-balance-algorithm id="randomStrategy" type="RANDOM" />
     
-	<!-- readwrite-splitting rule configuration -->
+    <!-- readwrite-splitting rule configuration -->
     <readwrite-splitting:rule id="readWriteSplittingRule">
         <readwrite-splitting:data-source-rule id="ds_0" write-data-source-name="write_ds0" read-data-source-names="read_ds0_0, read_ds0_1" load-balance-algorithm-ref="randomStrategy" />
-		<readwrite-splitting:data-source-rule id="ds_1" write-data-source-name="write_ds1" read-data-source-names="read_ds1_0, read_ds1_1" load-balance-algorithm-ref="randomStrategy" />
+        <readwrite-splitting:data-source-rule id="ds_1" write-data-source-name="write_ds1" read-data-source-names="read_ds1_0, read_ds1_1" load-balance-algorithm-ref="randomStrategy" />
     </readwrite-splitting:rule>
     
-	<!-- sharding strategy configuration -->
-	<sharding:standard-strategy id="databaseStrategy" sharding-column="user_id" algorithm-ref="inlineDatabaseStrategyAlgorithm" />
+    <!-- sharding strategy configuration -->
+    <sharding:standard-strategy id="databaseStrategy" sharding-column="user_id" algorithm-ref="inlineDatabaseStrategyAlgorithm" />
     <sharding:standard-strategy id="orderTableStrategy" sharding-column="order_id" algorithm-ref="inlineOrderTableStrategyAlgorithm" />
     <sharding:standard-strategy id="orderItemTableStrategy" sharding-column="order_item_id" algorithm-ref="inlineOrderItemTableStrategyAlgorithm" />
 
@@ -114,8 +113,8 @@ weight = 6
         </encrypt:table>
     </encrypt:rule>
     
-	<!-- datasource configuration -->
-	<!-- the element data-source-names's value is all of the datasource name -->
+    <!-- datasource configuration -->
+    <!-- the element data-source-names's value is all of the datasource name -->
     <shardingsphere:data-source id="readQueryDataSource" data-source-names="write_ds0, read_ds0_0, read_ds0_1, write_ds1, read_ds1_0, read_ds1_1" 
         rule-refs="readWriteSplittingRule, shardingRule, encryptRule" >
         <props>
