commit e5e65b01148f8350349c2717ede83ab70f91d265
Author: Mike0601 <40025573+Mike0601@users.noreply.github.com>
Date:   Thu Jul 21 17:55:54 2022 +0800

    Update _index.en.md (#19439)

diff --git a/docs/document/content/features/scaling/_index.en.md b/docs/document/content/features/scaling/_index.en.md
index eb1010352fd..a44e49c3fac 100644
--- a/docs/document/content/features/scaling/_index.en.md
+++ b/docs/document/content/features/scaling/_index.en.md
@@ -1,36 +1,55 @@
 +++
 pre = "<b>4.8. </b>"
-title = "Scaling"
+title = "Data Migration"
 weight = 8
 chapter = true
 +++
 
-## Background
+## Definition
 
-There is a problem which how to migrate data from stand-alone database to sharding data nodes safely and simply;
-For applications which have used Apache ShardingSphere, scale out elastically is a mandatory requirement.
+Data migration refers to the preparation of data extraction from one storage cluster, the writing of that data to a new storage cluster and the verification of data consistency.
 
-## Challenges
+## Related Concepts
 
-Apache ShardingSphere provides great flexibility in sharding algorithms, but it gives a great challenge to scaling out.
-So it's the first challenge that how to find a way can support kinds of sharding algorithms and scale data nodes efficiently.
+### Nodes
 
-What's more, During the scaling process, it should not affect the running applications. 
-So It is another big challenge for scaling to reduce the time window of data unavailability during the scaling as much as possible, or even completely unaware.
+Instances for running compute or storage tier component processes. These can either be physical machines, virtual machines, or containers, etc.
 
-Finally, scaling should not affect the existing data. How to ensure the availability and correctness of data is the third challenge of scaling.
+### Cluster
+Multiple nodes that are assembled together to provide a specified service.
 
-ShardingSphere-Scaling is a common solution for migrating or scaling data.
+### Source
 
-![Overview](https://shardingsphere.apache.org/document/current/img/scaling/overview_v2.png)
+The storage cluster where the original data resides.
 
-## Goal
+### Target
 
-**The main design goal of ShardingSphere-Scaling is providing common solution which can support kinds of sharding algorithm and reduce the impact as much as possible during scaling.**
+The target storage cluster to which the original data is to be migrated.
 
-## Status
+### Data Migration Process
 
-ShardingSphere-Scaling since version **4.1.0**.
-Current status is in **alpha** development.
+The entire process of replicating data from one storage cluster to another.
 
-**Source Codes: https://github.com/apache/shardingsphere/tree/master/shardingsphere-kernel/shardingsphere-data-pipeline**
+### Stock Data
+
+The data that was already in the data node before the data migration operation started.
+
+### Incremental Data
+
+New data generated by operational systems during the execution of data migration operations.
+
+## Limitations
+### Procedures Supported
+
+* Migration of peripheral data to databases managed by Apache ShardingSphere.
+* Migration of integer or string primary key tables.
+
+### Procedures not supported
+
+* Migration without primary key tables.
+* Migration of composite primary key tables.
+* Migration on top of the current storage node is not supported, so a brand new database cluster needs to be prepared as the migration target cluster.
+
+## References
+
+[Configurations of data migration ](/en/user-manual/shardingsphere-proxy/scaling/)
