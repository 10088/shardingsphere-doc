<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>使用手册 on ElasticJob</title>
    <link>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/</link>
    <description>Recent content in 使用手册 on ElasticJob</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>作业 API</title>
      <link>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/job-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/job-api/</guid>
      <description>0. 环境要求 a. Java 请使用 Java 8 及其以上版本。
b. Zookeeper 请使用 Zookeeper 3.6.0 及其以上版本。详情参见
c. Maven 请使用 Maven 3.0.4 及其以上版本。详情参见
1. 作业开发 ElasticJob-Lite 和 ElasticJob-Cloud 提供统一作业接口，开发者仅需对业务作业进行一次开发，之后可根据不同的配置以及部署至不同的 Lite 或 Cloud 环境。
ElasticJob 提供 Simple、Dataflow 和 Script 3 种作业类型。 方法参数shardingContext包含作业配置、片和运行时信息。可通过getShardingTotalCount(), getShardingItem()等方法分别获取分片总数，运行在本作业服务器的分片序列号等。
a. Simple类型作业 意为简单实现，未经任何封装的类型。需实现SimpleJob接口。该接口仅提供单一方法用于覆盖，此方法将定时执行。与Quartz原生接口相似，但提供了弹性扩缩容和分片等功能。
public class MyElasticJob implements SimpleJob { @Override public void execute(ShardingContext context) { switch (context.getShardingItem()) { case 0: // do something by sharding item 0  break; case 1: // do something by sharding item 1  break; case 2: // do something by sharding item 2  break; // case n: .</description>
    </item>
    
    <item>
      <title>作业监听器</title>
      <link>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/job-listener/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/job-listener/</guid>
      <description>可通过配置多个任务监听器，在任务执行前和执行后执行监听的方法。监听器分为每台作业节点均执行和分布式场景中仅单一节点执行2种。
1. 每台作业节点均执行的监听 若作业处理作业服务器的文件，处理完成后删除文件，可考虑使用每个节点均执行清理任务。此类型任务实现简单，且无需考虑全局分布式任务是否完成，请尽量使用此类型监听器。
步骤：
 定义监听器  public class MyElasticJobListener implements ElasticJobListener { @Override public void beforeJobExecuted(ShardingContexts shardingContexts) { // do something ...  } @Override public void afterJobExecuted(ShardingContexts shardingContexts) { // do something ...  } }  将监听器作为参数传入JobScheduler  public class JobMain { public static void main(String[] args) { new JobScheduler(createRegistryCenter(), createJobConfiguration(), new MyElasticJobListener()).init(); } private static CoordinatorRegistryCenter createRegistryCenter() { CoordinatorRegistryCenter regCenter = new ZookeeperRegistryCenter(new ZookeeperConfiguration(&amp;#34;zk_host:2181&amp;#34;, &amp;#34;elastic-job-demo&amp;#34;)); regCenter.</description>
    </item>
    
    <item>
      <title>事件追踪</title>
      <link>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/event-trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/event-trace/</guid>
      <description>ElasticJob 提供了事件追踪功能，可通过事件订阅的方式处理调度过程的重要事件，用于查询、统计和监控。 ElasticJob 目前提供了基于关系型数据库两种事件订阅方式记录事件。
通过代码配置开启事件追踪 ElasticJob-Lite 在配置中提供了 TracingConfiguration，目前支持数据库方式配置。
// 初始化数据源  DataSource dataSource = ...; // 定义日志数据库事件溯源配置  TracingConfiguration tracingConfig = new TracingConfiguration&amp;lt;&amp;gt;(&amp;#34;RDB&amp;#34;, dataSource); // 初始化注册中心  CoordinatorRegistryCenter regCenter = ...; // 初始化作业配置  JobConfiguration jobConfig = ...; new JobScheduler(regCenter, jobConfig, tracingConfig).init(); 具体配置方式请参见开发指南.
事件追踪的 event_trace_rdb_url 属性对应库自动创建 JOB_EXECUTION_LOG 和 JOB_STATUS_TRACE_LOG 两张表以及若干索引。
JOB_EXECUTION_LOG 字段含义
   字段名称 字段类型 是否必填 描述     id VARCHAR(40) 是 主键   job_name VARCHAR(100) 是 作业名称   task_id VARCHAR(1000) 是 任务名称,每次作业运行生成新任务   hostname VARCHAR(255) 是 主机名称   ip VARCHAR(50) 是 主机IP   sharding_item INT 是 分片项   execution_source VARCHAR(20) 是 作业执行来源。可选值为NORMAL_TRIGGER, MISFIRE, FAILOVER   failure_cause VARCHAR(2000) 否 执行失败原因   is_success BIT 是 是否执行成功   start_time TIMESTAMP 是 作业开始执行时间   complete_time TIMESTAMP 否 作业结束执行时间    JOB_EXECUTION_LOG 记录每次作业的执行历史。分为两个步骤：</description>
    </item>
    
    <item>
      <title>操作 API</title>
      <link>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/operation-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/usage/operation-api/</guid>
      <description>Java API(孵化中) 1. 配置类API JobConfigurationAPI 作业配置的API YamlJobConfiguration getJobConfiguration(String jobName) 获取作业设置.   Parameters: jobName — 作业名称
  Returns: 作业设置对象
  void updateJobConfiguration(YamlJobConfiguration yamlJobConfiguration) 更新作业设置.  Parameters: jobConfiguration — 作业设置对象  void removeJobConfiguration(String jobName) 删除作业设置.  Parameters: jobName — 作业名称  2. 操作类API 2.1 JobOperateAPI 操作作业的API void trigger(OptionaljobName, OptionalserverIp) 作业立刻执行.作业在不与上次运行中作业冲突的情况下才会启动, 并在启动后自动清理此标记.  Parameters:  jobName — 作业名称 serverIp — 作业服务器IP地址    void disable(OptionaljobName, OptionalserverIp) 作业禁用.会重新分片.  Parameters:  jobName — 作业名称 serverIp — 作业服务器IP地址    void enable(OptionaljobName, OptionalserverIp) 作业启用.</description>
    </item>
    
  </channel>
</rss>